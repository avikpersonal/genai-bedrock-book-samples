{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ed3a60a-5001-46ff-ae70-61d861a00c53",
   "metadata": {
    "tags": []
   },
   "source": [
    "# File Name: simple_prompt_mgmt.ipynb\n",
    "### Location: Chapter 15\n",
    "### Purpose: \n",
    "#####       1. Create a prompt using Prompt management\n",
    "#####       2. Modify a prompt using Prompt management \n",
    "#####       3. Create a version of a prompt in Prompt management  \n",
    "#####       4. Retrieve detail of prompt \n",
    "#####       5. Testing the prompt with simple way \n",
    "#####       6. Delete a version of a prompt in Prompt management\n",
    "##### Dependency: Not Applicable\n",
    "# <ins>-----------------------------------------------------------------------------------</ins>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99464e3-0679-4a67-bb38-8d96892eefa5",
   "metadata": {},
   "source": [
    "# <ins>Amazon SageMaker Classic</ins>\n",
    "#### Those who are new to Amazon SageMaker Classic. Follow the link for the details. https://docs.aws.amazon.com/sagemaker/latest/dg/studio.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91003ca1-0026-46eb-bd09-81861135cb22",
   "metadata": {},
   "source": [
    "# <ins>Environment setup of Kernel</ins>\n",
    "##### Fill \"Image\" as \"Data Science\"\n",
    "##### Fill \"Kernel\" as \"Python 3\"\n",
    "##### Fill \"Instance type\" as \"ml-t3-medium\"\n",
    "##### Fill \"Start-up script\" as \"No Scripts\"\n",
    "##### Click \"Select\"\n",
    "\n",
    "###### Refer https://docs.aws.amazon.com/sagemaker/latest/dg/notebooks-create-open.html for details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c865b7f5-755a-498c-bff6-7647281b15b9",
   "metadata": {},
   "source": [
    "# <ins>Mandatory installation on the kernel through pip</ins>\n",
    "\n",
    "##### This lab will work with below software version. But, if you are trying with latest version of boto3, awscli, and botocore. This code may fail. You might need to change the corresponding api. \n",
    "\n",
    "##### You will see pip dependency errors. you can safely ignore these errors and continue executing rest of the cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ade0112-a4be-4ce8-be92-8cbf28b2acfa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install --no-build-isolation --force-reinstall -q \\\n",
    "    \"boto3>=1.28.57\" \\\n",
    "    \"awscli>=1.29.57\" \\\n",
    "    \"botocore>=1.31.57\"  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4e3b85-4e64-42ef-9355-ed2a61c68b23",
   "metadata": {},
   "source": [
    "# <ins>Disclaimer</ins>\n",
    "\n",
    "##### You will see pip dependency errors. you can safely ignore these errors and continue executing rest of the cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88ee934-e99c-49ce-9e94-27ffc5baabe1",
   "metadata": {},
   "source": [
    "# <ins>Restart the kernel</ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaf41bf-d2d2-46fa-b1d4-1dd19c45a069",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# restart kernel\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5af76d-b2a9-4740-b8bf-134932804719",
   "metadata": {},
   "source": [
    "# <ins>Python package import</ins>\n",
    "\n",
    "##### boto3 offers various clients for Amazon Bedrock to execute various actions.\n",
    "##### botocore is a low-level interface to AWS tools, while boto3 is built on top of botocore and provides additional features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7268959-6ef0-4cbd-bd53-3b31369b4513",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import boto3\n",
    "import botocore\n",
    "import warnings\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d1b877-deab-4961-a249-7663e812fbb8",
   "metadata": {},
   "source": [
    "### Ignore warning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71587271-9f02-46dc-9eaf-5a5291132f8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a707d91-23c2-4786-bd2a-6287ca51ef82",
   "metadata": {},
   "source": [
    "## Define important environment variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4247b5-5fe7-4ec8-9f25-bff782734606",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Try-except block to handle potential errors\n",
    "try:\n",
    "    # Create a new Boto3 session to interact with AWS services\n",
    "    # This session is responsible for managing credentials and region configuration\n",
    "    boto3_session = boto3.session.Session()\n",
    "\n",
    "    # Retrieve the current AWS region from the session (e.g., 'us-east-1', 'us-west-2')\n",
    "    aws_region_name = boto3_session.region_name\n",
    "    \n",
    "    # Initialize Bedrock and Bedrock Runtime and Bedrock Agent clients using Boto3\n",
    "    # These clients will allow interactions with Bedrock-related AWS services\n",
    "    boto3_bedrock_client = boto3.client('bedrock', region_name=aws_region_name)\n",
    "    boto3_bedrock_runtime_client = boto3.client('bedrock-runtime', region_name=aws_region_name)\n",
    "    boto3_bedrock_agent_client = boto3.client(service_name=\"bedrock-agent\", region_name=aws_region_name)\n",
    "    \n",
    "    # Define the name of the prompt \n",
    "    prompt_name = \"iPhone_accessories_recommendation\"\n",
    "\n",
    "    # Store all relevant variables in a dictionary for easier access and management\n",
    "    variables_store = {\n",
    "        \"aws_region_name\": aws_region_name,                          # AWS region name\n",
    "        \"boto3_bedrock_client\": boto3_bedrock_client,                # Bedrock client instance\n",
    "        \"boto3_bedrock_runtime_client\": boto3_bedrock_runtime_client,  # Bedrock Runtime client instance\n",
    "        \"boto3_bedrock_agent_client\": boto3_bedrock_agent_client,  # Bedrock agent client instance\n",
    "        \"prompt_name\": prompt_name,\n",
    "        \"boto3_session\": boto3_session                               # Current Boto3 session object\n",
    "    }\n",
    "\n",
    "    # Print all stored variables for debugging and verification\n",
    "    for var_name, value in variables_store.items():\n",
    "        print(f\"{var_name}: {value}\")\n",
    "\n",
    "# Handle any exceptions that occur during the execution\n",
    "except Exception as e:\n",
    "    # Print the error message if an unexpected error occurs\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674cb33d-c1f3-4b22-806a-cc13983dcc33",
   "metadata": {},
   "source": [
    "# Create a prompt using Prompt management\n",
    "\n",
    "#### 1. Purpose: To create a prompt with placeholders for dynamic inputs, allowing tailored text generation for a specific use case (e.g., recommending iPhone accessories).\n",
    "\n",
    "#### 2. Prompt Details:\n",
    "###### Name: \"iPhone_accessories_recommendation\"\n",
    "###### Description: \"Initial prompt\"\n",
    "###### Variants: Defines configurations for inference, such as the model, template type, and placeholders.\n",
    "\n",
    "#### 3. Inference Configuration:\n",
    "###### Uses the amazon.titan-text-express-v1 model.\n",
    "###### Configures the output generation randomness using a temperature setting (0.8).\n",
    "\n",
    "#### 4. Template Configuration:\n",
    "###### A template string with placeholders:\n",
    "###### \"Recommend {{number_of_accessories}} popular accessories under {{dollar_amount}} for a {{customer_persona}} who recently bought an iPhone.\"\n",
    "\n",
    "#### 5. Workflow:\n",
    "###### Calls the create_prompt method using Boto3's Bedrock client to register the prompt and its variants.\n",
    "###### Retrieves and prints the prompt_id from the API response for reference.\n",
    "\n",
    "Refer: https://boto3.amazonaws.com/v1/documentation/api/1.35.6/reference/services/bedrock-agent/client/create_prompt.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c9bdd2-ee28-4a26-afd2-9ba957e421b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    # Create the prompt with different variants and configurations\n",
    "    response = boto3_bedrock_agent_client.create_prompt(\n",
    "        name=prompt_name,  # Name of the prompt\n",
    "        description=\"Initial prompt\",  # Description of the prompt\n",
    "        variants=[  # Define variants of the prompt\n",
    "            {\n",
    "                \"name\": \"Variant1\",  # Name of the variant\n",
    "                \"modelId\": \"amazon.titan-text-express-v1\",  # Model to be used for inference\n",
    "                \"templateType\": \"TEXT\",  # Specify template type as TEXT\n",
    "                \"inferenceConfiguration\": {\n",
    "                    \"text\": {\n",
    "                        \"temperature\": 0.8  # Set temperature for randomness in the generated output\n",
    "                    }\n",
    "                },\n",
    "                \"templateConfiguration\": {\n",
    "                    \"text\": {\n",
    "                        \"text\": \"Recommend {{number_of_accessories}} popular accessories under {{dollar_amount}} for a {{customer_persona}} who recently bought an iPhone.\"  # Prompt template with placeholders\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Retrieve the prompt ID from the response\n",
    "    prompt_id = response.get(\"id\")\n",
    "    print(f\"Prompt created successfully with ID: {prompt_id}\")\n",
    "\n",
    "except boto3.exceptions.Boto3Error as e:\n",
    "    # Handle any boto3 exceptions that may arise during API interaction\n",
    "    print(f\"An error occurred while creating the prompt: {str(e)}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    # Catch any other unexpected errors\n",
    "    print(f\"An unexpected error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ade6ef9-b0f1-4c42-b17a-7eb5e4f3b155",
   "metadata": {},
   "source": [
    "# List all the prompts \n",
    "\n",
    "Refer: https://boto3.amazonaws.com/v1/documentation/api/1.35.6/reference/services/bedrock-agent/client/list_prompts.html#list-prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20b9f55-238c-4e0e-8bab-23611b881ea3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# List prompts that you've created\n",
    "boto3_bedrock_agent_client.list_prompts() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87384c6-eda7-4fe0-a32d-245d0e94d968",
   "metadata": {},
   "source": [
    "# get detail information of a speciic prompt\n",
    "\n",
    "Refer: https://boto3.amazonaws.com/v1/documentation/api/1.35.6/reference/services/bedrock-agent/client/get_prompt.html#get-prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aba8d03-abf1-49ec-8420-ac02109b29f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get information about the prompt that you created\n",
    "response = boto3_bedrock_agent_client.get_prompt(promptIdentifier=prompt_id)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19832254-bb65-4762-b3ff-520b35ae3f79",
   "metadata": {},
   "source": [
    "# Create a version of a prompt in Prompt management\n",
    "\n",
    "#### 1. Purpose: Create a new version of an existing prompt using AWS Bedrock's create_prompt_version method and provides error handling for any issues encountered.\n",
    "###### Uses create_prompt_version via the Bedrock Agent client (boto3_bedrock_agent_client) to generate a new version of the prompt.\n",
    "\n",
    "Refer: https://boto3.amazonaws.com/v1/documentation/api/1.35.6/reference/services/bedrock-agent/client/create_prompt_version.html#create-prompt-version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1a5c1d-a1c4-4fe1-aaf1-8f4d47aca58b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    # Attempt to create a new version of the prompt\n",
    "    response = boto3_bedrock_agent_client.create_prompt_version(promptIdentifier=prompt_id)\n",
    "    \n",
    "    # Extract the version and ARN from the response\n",
    "    prompt_version = response.get(\"version\")  # Retrieve the newly created version number\n",
    "    prompt_version_arn = response.get(\"arn\")  # Retrieve the ARN of the newly created version\n",
    "\n",
    "    # Print the response details for verification\n",
    "    print(\"Prompt version created successfully!\")\n",
    "    print(f\"Version: {prompt_version}\")\n",
    "    print(f\"ARN: {prompt_version_arn}\")\n",
    "\n",
    "except Exception as e:\n",
    "    # Handle any exceptions that occur during the request\n",
    "    print(f\"Error creating prompt version: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953686fd-10d5-4e0d-a939-e9a32ee92231",
   "metadata": {},
   "source": [
    "# List prompts that you've created\n",
    "#### 1. Details of a specific version of a prompt using AWS Bedrock's get_prompt method and handles potential errors during the API call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9679af3b-d94e-4c49-b6b9-abbf927c6c20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    # Retrieve the details of the specified prompt version\n",
    "    response = boto3_bedrock_agent_client.get_prompt(\n",
    "        promptIdentifier=prompt_id,\n",
    "        promptVersion=prompt_version\n",
    "    )\n",
    "\n",
    "    # Print the response to view the prompt details\n",
    "    print(\"Prompt details retrieved successfully!\")\n",
    "    print(response)\n",
    "\n",
    "except Exception as e:\n",
    "    # Handle any errors that occur during the API call\n",
    "    print(f\"Error retrieving prompt details: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4600a796-708b-468c-9cfd-dd816e94ca8c",
   "metadata": {},
   "source": [
    "# Modify a prompt using Prompt management\n",
    "\n",
    "#### 1. Use cases: Updating Model ID and inferenceConfiguration\n",
    "\n",
    "#### 2. Purpose: Updates an existing prompt by adding a new variant using the AWS Bedrock API. It attempts to modify the configuration of the prompt, specifically by adding a new variant with a different model and inference settings.\n",
    "##### Calls update_prompt from the Bedrock Agent client (client):\n",
    "##### name: Specifies the name of the prompt to be updated.\n",
    "##### promptIdentifier: Specifies the unique identifier (ID) of the prompt.\n",
    "##### variants: A list of new variants to add to the prompt. Each variant includes:\n",
    "##### name: The name of the variant (e.g., \"Variant2\").\n",
    "##### modelId: The model ID used for inference (e.g., \"amazon.titan-text-premier-v1:0\").\n",
    "##### templateType: Specifies the type of template (e.g., TEXT).\n",
    "##### inferenceConfiguration: Configurations for text generation (e.g., temperature, topP).\n",
    "##### templateConfiguration: The template for the prompt, with placeholders to be filled dynamically during execution (e.g., for recommending accessories).\n",
    "\n",
    "Refer: https://boto3.amazonaws.com/v1/documentation/api/1.35.6/reference/services/bedrock-agent/client/update_prompt.html#update-prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5887a59-ce9a-4595-aaef-1650006aacb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    # Update the prompt with a new variant\n",
    "    response = boto3_bedrock_agent_client.update_prompt(\n",
    "        name=prompt_name,  # The name of the prompt you're updating\n",
    "        promptIdentifier=prompt_id,    # The unique identifier for the prompt\n",
    "        variants=[  # Define variants of the prompt\n",
    "            {\n",
    "                \"name\": \"Variant2\",  # Name of the variant\n",
    "                \"modelId\": \"amazon.titan-text-premier-v1:0\",  # Model used for inference\n",
    "                \"templateType\": \"TEXT\",  # Define the template type as TEXT (for text generation)\n",
    "                \"inferenceConfiguration\": {\n",
    "                    \"text\": {\n",
    "                        \"temperature\": 0.8,  # Temperature controls the randomness of the response\n",
    "                        \"topP\": 0.9  # Controls diversity via nucleus sampling\n",
    "                    }\n",
    "                },\n",
    "                \"templateConfiguration\": {\n",
    "                    \"text\": {\n",
    "                        # Define the prompt template with placeholders for dynamic values\n",
    "                        \"text\": \"Recommend {{number_of_accessories}} popular accessories under {{dollar_amount}} for a {{customer_persona}} who recently bought an iPhone.\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Print the response to confirm the update\n",
    "    print(\"Prompt updated successfully!\")\n",
    "    print(response)\n",
    "\n",
    "except Exception as e:\n",
    "    # Handle any errors during the update process\n",
    "    print(f\"Error updating prompt: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1954147-a8d4-4aba-8c95-2aee5037bd1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a version of a prompt in Prompt management\n",
    "try:\n",
    "    # Attempt to create a new version of the prompt\n",
    "    response = boto3_bedrock_agent_client.create_prompt_version(promptIdentifier=prompt_id)\n",
    "    \n",
    "    # Extract the version and ARN from the response\n",
    "    prompt_version = response.get(\"version\")  # Retrieve the newly created version number\n",
    "    prompt_version_arn = response.get(\"arn\")  # Retrieve the ARN of the newly created version\n",
    "\n",
    "    # Print the response details for verification\n",
    "    print(\"Prompt version created successfully!\")\n",
    "    print(f\"Version: {prompt_version}\")\n",
    "    print(f\"ARN: {prompt_version_arn}\")\n",
    "\n",
    "except Exception as e:\n",
    "    # Handle any exceptions that occur during the request\n",
    "    print(f\"Error creating prompt version: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f9f428-853a-48e1-af97-6979aa397f84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# List prompts that you've created\n",
    "try:\n",
    "    # Retrieve the details of the specified prompt version\n",
    "    response = boto3_bedrock_agent_client.get_prompt(\n",
    "        promptIdentifier=prompt_id,\n",
    "        promptVersion=prompt_version\n",
    "    )\n",
    "\n",
    "    # Print the response to view the prompt details\n",
    "    print(\"Prompt details retrieved successfully!\")\n",
    "    print(response)\n",
    "\n",
    "except Exception as e:\n",
    "    # Handle any errors that occur during the API call\n",
    "    print(f\"Error retrieving prompt details: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35da8db6-f410-4252-8993-eee8b4ddcea4",
   "metadata": {},
   "source": [
    "# Note: \n",
    "### Compare between version 1 and version 2. You will see change of Model Id and inferenceConfiguration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d539f0b5-6fc9-4dd8-b25c-95e5836ab277",
   "metadata": {},
   "source": [
    "# Test a prompt using Prompt management\n",
    "\n",
    "### Method 1. You can test the prompt through Amazon Bedrock Prompt Flow. You will learn in Chapter 16\n",
    "### Method 2. You can test the prompt through Amazon Bedrock console. Refer https://docs.aws.amazon.com/bedrock/latest/userguide/prompt-management-test.html\n",
    "### Method 3. Here, you will learn one simple way to retrive information about prompt and test. This is only to showcase the capability. You will always use Method 1 mentioned above. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc76335-b9f6-4f61-b5ee-276a3a75c793",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Common functions\n",
    "\n",
    "# generate_dynamic_prompt\n",
    "'''\n",
    "The function generate_dynamic_prompt is designed to replace placeholders within a prompt template with specific values from a dictionary of parameters. \n",
    "This function allows for dynamic generation of prompts by filling in values for placeholders like {{number_of_accessories}}, {{dollar_amount}}, and {{customer_persona}}.\n",
    "generate_dynamic_prompt(template, parameters): This function takes two arguments:\n",
    "template: A string that contains placeholders (e.g., {{number_of_accessories}}).\n",
    "parameters: A dictionary where the keys match the placeholders in the template, and the values are the ones that will replace those placeholders.\n",
    "The function loops through the dictionary (parameters.items()), replacing each placeholder (e.g., {{number_of_accessories}}) in the template with its corresponding value (3 in the case of number_of_accessories).\n",
    "'''\n",
    "\n",
    "# Dynamic Parameters:\n",
    "'''\n",
    "The dynamic_parameters dictionary defines the values that will replace the placeholders in the prompt template.\n",
    "\"number_of_accessories\": 3: This will replace {{number_of_accessories}} with 3.\n",
    "\"dollar_amount\": 50: This will replace {{dollar_amount}} with 50.\n",
    "\"customer_persona\": \"budget-conscious college student\": This will replace {{customer_persona}} with \"budget-conscious college student\".\n",
    "'''\n",
    "\n",
    "# Function to dynamically populate placeholders in the prompt\n",
    "def generate_dynamic_prompt(template, parameters):\n",
    "    \"\"\"\n",
    "    Replace placeholders in the template with actual values from parameters.\n",
    "    :param template: The template string with placeholders (e.g., {{placeholder}})\n",
    "    :param parameters: A dictionary of values to replace placeholders with\n",
    "    :return: A populated string\n",
    "    \"\"\"\n",
    "    for key, value in parameters.items():\n",
    "        template = template.replace(f\"{{{{{key}}}}}\", str(value))\n",
    "    return template\n",
    "\n",
    "# Define dynamic input parameters for the prompt\n",
    "dynamic_parameters = {\n",
    "    \"number_of_accessories\": 3,\n",
    "    \"dollar_amount\": 50,\n",
    "    \"customer_persona\": \"budget-conscious college student\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47aa0dfd-a0b1-4e9b-8cf2-875f305c00fd",
   "metadata": {},
   "source": [
    "# Interact with the AWS Bedrock service to retrieve information about a specific prompt, generate a dynamic prompt based on a template, and invoke the model to generate a response. \n",
    "### 1. Get information about the prompt version\n",
    "### 2. Extract information from the response\n",
    "### 3. Retrieve or set default values for temperature and topP\n",
    "### 4. Define dynamic parameters\n",
    "### 5. Generate the dynamic prompt:\n",
    "### 6. Prepare the input payload for model invocation\n",
    "### 7. Invoke the model\n",
    "### 8. Parse and display the model output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e227cc8b-246f-4be4-8b0b-a6ea3bc076d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    # Get information about the specified prompt version\n",
    "    response = boto3_bedrock_agent_client.get_prompt(\n",
    "        promptIdentifier=prompt_id,\n",
    "        promptVersion=prompt_version\n",
    "    )\n",
    "    \n",
    "    # Extract relevant information from the response\n",
    "    prompt_arn = response.get(\"arn\")\n",
    "    model_id = response['variants'][0]['modelId']\n",
    "    template = response['variants'][0]['templateConfiguration']['text']['text']\n",
    "    \n",
    "    # Print details for verification\n",
    "    print(f\"Prompt ARN: {prompt_arn}\")\n",
    "    print(f\"Model ID: {model_id}\")\n",
    "    print(f\"Template: {template}\")\n",
    "    \n",
    "    # Extract the inference configuration settings (temperature, topP)\n",
    "    inferenceConfiguration_outcome = response['variants'][0]['inferenceConfiguration']['text']\n",
    "    temperature = inferenceConfiguration_outcome.get('temperature', 0.5)  # Default value if 'temperature' is not present\n",
    "    topP = inferenceConfiguration_outcome.get('topP', 0.5)  # Default value if 'topP' is not present\n",
    "    \n",
    "    # Define dynamic parameters for the prompt (example: number_of_accessories, dollar_amount)\n",
    "    dynamic_parameters = {\n",
    "        \"number_of_accessories\": 5,\n",
    "        \"dollar_amount\": 100,\n",
    "        \"customer_persona\": \"tech-savvy\"\n",
    "    }\n",
    "\n",
    "    # Generate the dynamic prompt based on the template and dynamic parameters\n",
    "    dynamic_prompt = generate_dynamic_prompt(template, dynamic_parameters)\n",
    "    print(f\"Generated Prompt: {dynamic_prompt}\\n\")\n",
    "\n",
    "    # Prepare the input payload for the model invocation\n",
    "    body = json.dumps({\n",
    "        \"inputText\": dynamic_prompt,\n",
    "        \"textGenerationConfig\": {\n",
    "            \"topP\": topP,          # Controls the nucleus sampling probability (diversity of output)\n",
    "            \"temperature\": temperature  # Controls the creativity of the model's response\n",
    "        }\n",
    "    })\n",
    "    \n",
    "    modelId = model_id  # Model ID to be used in the model invocation\n",
    "    accept = \"application/json\"\n",
    "    contentType = \"application/json\"\n",
    "\n",
    "    # Invoke the model with the specified parameters using the Bedrock runtime client\n",
    "    response = boto3_bedrock_runtime_client.invoke_model(\n",
    "        body=body,\n",
    "        modelId=modelId,\n",
    "        accept=accept,\n",
    "        contentType=contentType\n",
    "    )\n",
    "    \n",
    "    # Parse the response body to extract the model's output\n",
    "    response_body = json.loads(response.get(\"body\").read())\n",
    "    output_text = response_body.get(\"results\", [{}])[0].get(\"outputText\", \"No output text available\")\n",
    "\n",
    "    # Display the output text from the model\n",
    "    print(\"Model Output:\", output_text)\n",
    "\n",
    "except boto3.exceptions.Boto3Error as boto3_err:\n",
    "    # Handle AWS-specific errors\n",
    "    print(f\"An AWS error occurred: {str(boto3_err)}\")\n",
    "\n",
    "except Exception as err:\n",
    "    # Handle unexpected errors\n",
    "    print(f\"An unexpected error occurred: {str(err)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a207bb-29c0-44d8-a206-d7280cfd8484",
   "metadata": {},
   "source": [
    "# Delete a version of a prompt in Prompt management"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d520db-8032-4c38-b4f9-53ef0acbb2dd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Delete a specific version of a prompt in Prompt management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdc0768-040f-42a1-aacc-6f517167803e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    # Delete the specified prompt version\n",
    "    response = boto3_bedrock_agent_client.delete_prompt(\n",
    "        promptIdentifier=prompt_id,\n",
    "        promptVersion=prompt_version\n",
    "    )\n",
    "    \n",
    "    # Print the response to confirm the deletion\n",
    "    print(\"Prompt version deleted successfully!\")\n",
    "    print(response)\n",
    "\n",
    "except boto3.exceptions.Boto3Error as boto3_err:\n",
    "    # Handle AWS-specific errors\n",
    "    print(f\"An AWS error occurred while deleting the prompt: {str(boto3_err)}\")\n",
    "\n",
    "except Exception as err:\n",
    "    # Handle unexpected errors\n",
    "    print(f\"An unexpected error occurred: {str(err)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e248c8af-7551-4432-9054-86222e734346",
   "metadata": {},
   "source": [
    "### Delete a prompt in Prompt management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73983ff-7068-491d-8a1b-a803abcbcc55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    # Delete the specified prompt\n",
    "    response = boto3_bedrock_agent_client.delete_prompt(\n",
    "        promptIdentifier=prompt_id\n",
    "    )\n",
    "    \n",
    "    # Print the response to confirm the deletion\n",
    "    print(\"Prompt deleted successfully!\")\n",
    "    print(response)\n",
    "\n",
    "except boto3.exceptions.Boto3Error as boto3_err:\n",
    "    # Handle AWS-specific errors\n",
    "    print(f\"An AWS error occurred while deleting the prompt: {str(boto3_err)}\")\n",
    "\n",
    "except Exception as err:\n",
    "    # Handle unexpected errors\n",
    "    print(f\"An unexpected error occurred: {str(err)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51745d43-360d-42a1-8617-a7a3a2769ab8",
   "metadata": {},
   "source": [
    "# End of NoteBook \n",
    "\n",
    "## Please ensure that you close the kernel after using this notebook to avoid any potential charges to your account.\n",
    "\n",
    "## Process: Go to \"Kernel\" at top option. Choose \"Shut Down Kernel\". \n",
    "##### Refer https://docs.aws.amazon.com/sagemaker/latest/dg/studio-ui.html"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
