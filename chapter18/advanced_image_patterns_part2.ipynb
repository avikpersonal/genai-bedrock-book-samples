{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ed3a60a-5001-46ff-ae70-61d861a00c53",
   "metadata": {
    "tags": []
   },
   "source": [
    "# File Name: advanced_image_patterns_part2.ipynb\n",
    "### Location: Chapter 18\n",
    "### Purpose: \n",
    "#####       1. Image Inpainting\n",
    "#####       2. Image Conditioning\n",
    "#####       3. Colour Conditioning\n",
    "#####       4. Image Outpainting\n",
    "#####       5. Background Removal \n",
    "#####       6. Combination of Text and Image\n",
    "\n",
    "##### Dependency: simple-sageMaker-bedrock.ipynb at Chapter 3 should work properly.\n",
    "# <ins>-----------------------------------------------------------------------------------</ins>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99464e3-0679-4a67-bb38-8d96892eefa5",
   "metadata": {},
   "source": [
    "# <ins>Amazon SageMaker Classic</ins>\n",
    "#### Those who are new to Amazon SageMaker Classic. Follow the link for the details. https://docs.aws.amazon.com/sagemaker/latest/dg/studio.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91003ca1-0026-46eb-bd09-81861135cb22",
   "metadata": {},
   "source": [
    "# <ins>Environment setup of Kernel</ins>\n",
    "##### Fill \"Image\" as \"Data Science\"\n",
    "##### Fill \"Kernel\" as \"Python 3\"\n",
    "##### Fill \"Instance type\" as \"ml-t3-medium\"\n",
    "##### Fill \"Start-up script\" as \"No Scripts\"\n",
    "##### Click \"Select\"\n",
    "\n",
    "###### Refer https://docs.aws.amazon.com/sagemaker/latest/dg/notebooks-create-open.html for details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c865b7f5-755a-498c-bff6-7647281b15b9",
   "metadata": {},
   "source": [
    "# <ins>Mandatory installation on the kernel through pip</ins>\n",
    "\n",
    "##### This lab will work with below software version. But, if you are trying with latest version of boto3, awscli, and botocore. This code may fail. You might need to change the corresponding api. \n",
    "\n",
    "##### You will see pip dependency errors. you can safely ignore these errors and continue executing rest of the cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ade0112-a4be-4ce8-be92-8cbf28b2acfa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install --no-build-isolation --force-reinstall -q \\\n",
    "    \"boto3>=1.28.57\" \\\n",
    "    \"awscli>=1.29.57\" \\\n",
    "    \"botocore>=1.31.57\" \\\n",
    "    \"utils\" \\\n",
    "    \"matplotlib\" \\\n",
    "    \"numpy<2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4e3b85-4e64-42ef-9355-ed2a61c68b23",
   "metadata": {},
   "source": [
    "# <ins>Disclaimer</ins>\n",
    "\n",
    "##### You will see pip dependency errors. you can safely ignore these errors and continue executing rest of the cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88ee934-e99c-49ce-9e94-27ffc5baabe1",
   "metadata": {},
   "source": [
    "# <ins>Restart the kernel</ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaf41bf-d2d2-46fa-b1d4-1dd19c45a069",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# restart kernel\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5af76d-b2a9-4740-b8bf-134932804719",
   "metadata": {},
   "source": [
    "# <ins>Python package import</ins>\n",
    "\n",
    "##### boto3 offers various clients for Amazon Bedrock to execute various actions.\n",
    "##### botocore is a low-level interface to AWS tools, while boto3 is built on top of botocore and provides additional features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7268959-6ef0-4cbd-bd53-3b31369b4513",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import io\n",
    "import base64\n",
    "import random\n",
    "import warnings\n",
    "import boto3\n",
    "import botocore\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg \n",
    "from PIL import Image, ImageOps\n",
    "import sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d1b877-deab-4961-a249-7663e812fbb8",
   "metadata": {},
   "source": [
    "### Ignore warning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71587271-9f02-46dc-9eaf-5a5291132f8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a707d91-23c2-4786-bd2a-6287ca51ef82",
   "metadata": {},
   "source": [
    "## Define important environment variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4247b5-5fe7-4ec8-9f25-bff782734606",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Try-except block to handle potential errors during execution\n",
    "try:\n",
    "    # Create a new Boto3 session to interact with AWS services\n",
    "    # This session manages credentials and region configuration for AWS interactions\n",
    "    boto3_session = boto3.session.Session()\n",
    "\n",
    "    # Retrieve the current AWS region from the session (e.g., 'us-east-1', 'us-west-2')\n",
    "    aws_region_name = boto3_session.region_name\n",
    "\n",
    "    # Initialize Bedrock and Bedrock Runtime clients using Boto3\n",
    "    # These clients enable interactions with AWS Bedrock-related services\n",
    "    boto3_bedrock_client = boto3.client('bedrock', region_name=aws_region_name)\n",
    "    boto3_bedrock_runtime_client = boto3.client('bedrock-runtime', region_name=aws_region_name)\n",
    "\n",
    "    # Create a SageMaker session and retrieve the execution role ARN\n",
    "    # The role ARN authorizes SageMaker to perform tasks on behalf of the user\n",
    "    sagemaker_role_arn = sagemaker.get_execution_role()\n",
    "\n",
    "    # Specify the Amazon Titan image generator model ID for multimodal processing\n",
    "    amazon_titan_image_model_id = \"amazon.titan-image-generator-v2:0\"\n",
    "\n",
    "    # Specify the Amazon Titan embedding model ID for multimodal indexing\n",
    "    multimodal_embed_model_id = \"amazon.titan-embed-image-v1\"\n",
    "\n",
    "    # Store all relevant variables in a dictionary for easier access and management\n",
    "    variables_store = {\n",
    "        \"aws_region_name\": aws_region_name,                           # AWS region name\n",
    "        \"boto3_bedrock_client\": boto3_bedrock_client,                 # Bedrock client instance\n",
    "        \"boto3_bedrock_runtime_client\": boto3_bedrock_runtime_client, # Bedrock Runtime client instance\n",
    "        \"boto3_session\": boto3_session,                               # Current Boto3 session object\n",
    "        \"sagemaker_role_arn\": sagemaker_role_arn,                     # SageMaker execution role ARN\n",
    "        \"multimodal_embed_model_id\": multimodal_embed_model_id,       # Titan embedding model ID\n",
    "        \"amazon_titan_image_model_id\": amazon_titan_image_model_id    # Titan image generator model ID\n",
    "    }\n",
    "\n",
    "    # Print all stored variables for debugging and verification\n",
    "    for var_name, value in variables_store.items():\n",
    "        print(f\"{var_name}: {value}\")\n",
    "\n",
    "# Handle any exceptions that occur during the execution\n",
    "except Exception as e:\n",
    "    # Print an error message if an unexpected error occurs\n",
    "    print(f\"An unexpected error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0acb001-3a3b-4738-90bb-11c219fd6631",
   "metadata": {},
   "source": [
    "# Common code "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82209c1-30f7-4b61-b831-073657927b5f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### The provided Python code allows you to plot multiple images side by side with corresponding headings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a3c7c2-8720-41ff-a66b-0ee8f30a47f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "def plot_multiple_images(images, headings, cols=3):\n",
    "    \"\"\"\n",
    "    Plots multiple images side by side with headings.\n",
    "\n",
    "    Parameters:\n",
    "    images (list): A list of image paths.\n",
    "    headings (list): A list of headings for each image.\n",
    "    cols (int): The number of columns to display the images in (default is 3).\n",
    "    \"\"\"\n",
    "    # Calculate number of rows needed\n",
    "    rows = (len(images) + cols - 1) // cols\n",
    "\n",
    "    # Create a figure and axes\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols * 5, rows * 5))\n",
    "\n",
    "    # Flatten axes array if there are multiple rows\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    # Loop through images and plot them\n",
    "    for i in range(len(images)):\n",
    "        # Read the image from file path\n",
    "        img = mpimg.imread(images[i])\n",
    "        \n",
    "        # Plot the image\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].axis('off')  # Hide axis\n",
    "        \n",
    "        # Add the heading\n",
    "        axes[i].set_title(headings[i], fontsize=14, weight='bold')\n",
    "\n",
    "    # Hide unused axes if the number of images is less than the number of axes\n",
    "    for i in range(len(images), len(axes)):\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "# plot_multiple_images(images, headings, cols=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efc5fdd-474d-47ae-971a-d4a697b3fa60",
   "metadata": {},
   "source": [
    "### base64 encoded string of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89c0351-b3e5-46d5-a7c0-68c73581ae1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "def encode_image(image_path):\n",
    "    # Open the image file in binary mode\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        # Encode the image to base64\n",
    "        encoded_image = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "    return encoded_image\n",
    "\n",
    "# Example usage\n",
    "## encoded_image = encode_image(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c000df-adbd-4271-9089-7f7d518d54f9",
   "metadata": {},
   "source": [
    "### Decode base64 to image and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c80ec28-4250-4a81-9336-21fd46b63b02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def decode_image(encoded_image_b64, save_path):\n",
    "    \"\"\"\n",
    "    Decodes a base64-encoded image and saves it to a specified file location.\n",
    "\n",
    "    Args:\n",
    "        encoded_image_b64 (str): The base64-encoded string of the image.\n",
    "        save_path (str): The path where the decoded image will be saved.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Decode the base64 image and open it as a PIL Image\n",
    "        decoded_image = Image.open(\n",
    "            io.BytesIO(\n",
    "                base64.decodebytes(bytes(encoded_image_b64, \"utf-8\"))\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Save the decoded image to the specified path\n",
    "        decoded_image.save(save_path)\n",
    "        print(f\"Image successfully saved to {save_path}\")\n",
    "    except (base64.binascii.Error, IOError) as e:\n",
    "        print(f\"Error decoding or saving the image: {e}\")\n",
    "        raise  # Optionally re-raise the exception for external handling\n",
    "\n",
    "# Example usage\n",
    "# decode_image(generated_image_b64, \"output_image.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b316a7c8-aaaa-46d4-9cde-46cbc2d55ab1",
   "metadata": {},
   "source": [
    "### The function invoke_bedrock_model is designed to call an Amazon Bedrock model for image generation, with robust error handling and clear feedback mechanisms. It accepts a Boto3 runtime client, a JSON payload (body), and an optional model ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780ce8ff-1252-43ed-8fdc-7a6a5e3f9837",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "def invoke_bedrock_model(boto3_bedrock_runtime_client, body, model_id):\n",
    "    \"\"\"\n",
    "    Invokes the Amazon Bedrock model for image generation with error handling.\n",
    "    \n",
    "    Args:\n",
    "        boto3_bedrock_runtime_client: The Boto3 Bedrock runtime client.\n",
    "        body (str): The request payload as a JSON string.\n",
    "        model_id (str): The model identifier to invoke (default: \"amazon.titan-image-generator-v1\").\n",
    "    \n",
    "    Returns:\n",
    "        str: The base64-encoded image data if successful.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Model invocation\n",
    "        response = boto3_bedrock_runtime_client.invoke_model(\n",
    "            body=body,\n",
    "            modelId=model_id,\n",
    "            accept=\"application/json\", \n",
    "            contentType=\"application/json\"\n",
    "        )\n",
    "        \n",
    "        # Output processing\n",
    "        response_body = json.loads(response.get(\"body\").read())  # Decode response body\n",
    "        img_b64 = response_body[\"images\"][0]  # Extract the first image (base64-encoded)\n",
    "        print(f\"Output (truncated): {img_b64[:80]}...\")  # Print truncated base64 string for debugging\n",
    "        \n",
    "        return img_b64  # Return the full base64-encoded image\n",
    "    \n",
    "    except KeyError as e:\n",
    "        print(f\"KeyError: Missing expected key in response - {e}\")\n",
    "        return None\n",
    "    \n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"JSONDecodeError: Failed to parse response body - {e}\")\n",
    "        return None\n",
    "    \n",
    "    except boto3.exceptions.Boto3Error as e:\n",
    "        print(f\"Boto3Error: AWS SDK error - {e}\")\n",
    "        return None\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected Error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9690618-31dd-4620-b849-a0ae59027278",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Section 4: Image Inpainting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889dfa21-b37b-484a-bf59-8819014eb4ec",
   "metadata": {
    "tags": []
   },
   "source": [
    "### You previously generated an image of a river at dusk using a prompt. Now, you want to enhance the image by adding a boat in the middle of the scene.\n",
    "### The original image is located at data/generated_image/generated_image_15.png.\n",
    "### To achieve this, you will use the image inpainting technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c1e1a3-dab0-4b72-b228-b8367a487371",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "image_inpainting_source_image = \"data/generated_image/generated_image_15.png\"\n",
    "image_inpainting_mask_image = \"data/generated_image/generated_image_mask.png\"\n",
    "image_inpainting_target_image = \"data/generated_image/generated_image_inpainting.png\"\n",
    "\n",
    "# Read the image file and encode it in base64\n",
    "inpainting_source_encoded_image = encode_image(image_inpainting_source_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657fdd21-91a4-4bea-8103-674256c57583",
   "metadata": {},
   "source": [
    "### This script defines a function, create_inpainting_mask, to generate a segmentation mask for inpainting by filling a specified rectangular area with black and the rest with white. The function includes input validation for box coordinates to ensure proper execution. In the main execution, the script loads a source image, calculates the coordinates for centering a mask of specified dimensions, and creates the mask using the function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739ecef9-931d-4ca7-b390-fea036af7541",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def create_inpainting_mask(img, box):\n",
    "    \"\"\"\n",
    "    Generates a segmentation mask for inpainting.\n",
    "\n",
    "    Args:\n",
    "        img (PIL.Image.Image): The input image.\n",
    "        box (tuple): Coordinates for the box (left, top, right, bottom).\n",
    "\n",
    "    Returns:\n",
    "        PIL.Image.Image: A mask image with the specified box filled with black,\n",
    "                         and the rest filled with white.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Validate the input box coordinates\n",
    "        assert len(box) == 4, \"Box must have exactly 4 coordinates (left, top, right, bottom).\"\n",
    "        assert box[0] < box[2], \"Left coordinate must be less than the right coordinate.\"\n",
    "        assert box[1] < box[3], \"Top coordinate must be less than the bottom coordinate.\"\n",
    "        \n",
    "        # Generate the mask\n",
    "        img_size = img.size\n",
    "        mask = ImageOps.expand(\n",
    "            Image.new(\n",
    "                mode=\"RGB\", \n",
    "                size=(box[2] - box[0], box[3] - box[1]),  # Mask dimensions (width, height)\n",
    "                color='black'  # Black region for inpainting\n",
    "            ),\n",
    "            border=(\n",
    "                box[0],            # Left padding\n",
    "                box[1],            # Top padding\n",
    "                img_size[0] - box[2],  # Right padding\n",
    "                img_size[1] - box[3]   # Bottom padding\n",
    "            ),\n",
    "            fill='white'  # White for the rest of the image\n",
    "        )\n",
    "        return mask\n",
    "    except AssertionError as e:\n",
    "        print(f\"Error in box coordinates: {e}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "        raise\n",
    "\n",
    "# Main execution\n",
    "try:\n",
    "    # Load the source image\n",
    "    image = Image.open(image_inpainting_source_image)\n",
    "    image_size = image.size\n",
    "\n",
    "    # Define the size of the mask (width, height)\n",
    "    mask_width = 200\n",
    "    mask_height = 200\n",
    "\n",
    "    # Calculate the coordinates for the box to center the mask\n",
    "    box = (\n",
    "        (image_size[0] - mask_width) // 2,  # Left\n",
    "        (image_size[1] - mask_height) // 2,  # Top\n",
    "        (image_size[0] + mask_width) // 2,  # Right\n",
    "        (image_size[1] + mask_height) // 2   # Bottom\n",
    "    )\n",
    "\n",
    "    # Create the mask\n",
    "    mask = create_inpainting_mask(image, box)\n",
    "\n",
    "    # Display the mask (for debugging purposes)\n",
    "    mask.save(image_inpainting_mask_image)\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Image file not found: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280d15ef-bc2b-4885-92f6-365ffb8d3527",
   "metadata": {},
   "source": [
    "### Image Inpainting prompt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91fd888-c836-4fb1-b8b0-dca783d2e57c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inpaint_prompt = \"Add a boat \"\n",
    "negative_prompts = \"Poor quality, low resolution.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2ca9b7-e147-4bf2-b7b8-20e52c5cbdae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "inpainting_source_encoded_mask_image = encode_image(image_inpainting_mask_image)\n",
    "\n",
    "# Payload creation\n",
    "body = json.dumps({\n",
    "    \"taskType\": \"INPAINTING\",\n",
    "    \"inPaintingParams\": {\n",
    "        \"text\": inpaint_prompt,              # Optional\n",
    "        \"negativeText\": negative_prompts,    # Optional\n",
    "        \"image\": inpainting_source_encoded_image,      # Required\n",
    "        \"maskImage\": inpainting_source_encoded_mask_image,  # Input maskImage based on the values 0 (black) or 255 (white) only\n",
    "    },                                                 \n",
    "    \"imageGenerationConfig\": {\n",
    "        \"numberOfImages\": 1,\n",
    "        \"quality\": \"premium\",\n",
    "        \"height\": 1024,\n",
    "        \"width\": 1024,\n",
    "        \"cfgScale\": 7.5,\n",
    "        \"seed\": 42\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dbf66a-caf9-43a5-a2e4-9df3d95e8f3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "generated_image_b64 = invoke_bedrock_model(boto3_bedrock_runtime_client, body, amazon_titan_image_model_id )\n",
    "decode_image(generated_image_b64, image_inpainting_target_image)\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "images = [ image_inpainting_source_image , image_inpainting_mask_image , image_inpainting_target_image ]\n",
    "headings =[ \"Source Image\" , \"Mask Image\" , \"Generated Image\" ]\n",
    "plot_multiple_images(images, headings, cols=3)\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b8656b-714c-4b39-a31d-bf66531cc081",
   "metadata": {},
   "source": [
    "# Section 5: Image Conditioning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc41465-2742-4faf-9034-cead398ba2a6",
   "metadata": {},
   "source": [
    "### You previously generated an image of an elephant in a beautifull landscape using a prompt. Now, you want to enhance the image within the photoframe.\n",
    "### The original image is located at data/generated_image/generated_image_5.png.\n",
    "### To achieve this, you will use the image conditioning technique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892255dc-5575-4ae9-896c-b2b89bb54421",
   "metadata": {},
   "source": [
    "### Image Conditioning prompt for canny edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657d23cc-9d51-4f4e-9714-eba34c3176b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"A photo frame with a big elephant image.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b76153-5894-45f7-bce4-58b7dbcd5e36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_conditioning_source_image = \"data/generated_image/generated_image_5.png\"\n",
    "image_conditioning_target_image = \"data/generated_image/generated_image_conditioning.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abff1a8d-a2d7-441e-95c7-a7e46736a14a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "conditioning_source_encoded_image = encode_image(image_conditioning_source_image)\n",
    "\n",
    "# Generate image conditioned on reference image\n",
    "body = json.dumps({\n",
    "    \"taskType\": \"TEXT_IMAGE\",\n",
    "    \"textToImageParams\": {\n",
    "        \"text\": prompt,\n",
    "        \"conditionImage\": conditioning_source_encoded_image,\n",
    "        \"controlMode\": \"CANNY_EDGE\",\n",
    "        \"controlStrength\": 0.7,\n",
    "    },\n",
    "    \"imageGenerationConfig\": {\n",
    "        \"numberOfImages\": 1,\n",
    "        \"seed\": 42,\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a50aac2-3476-4dea-9150-d09c7d93ec7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "generated_image_b64 = invoke_bedrock_model(boto3_bedrock_runtime_client, body, amazon_titan_image_model_id )\n",
    "decode_image(generated_image_b64, image_conditioning_target_image)\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "images = [ image_conditioning_source_image , image_conditioning_target_image ]\n",
    "headings =[ \"Source Image\" ,  \"Generated Image\" ]\n",
    "plot_multiple_images(images, headings, cols=2)\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9551898-5922-432e-8fda-1ac3bfa30953",
   "metadata": {},
   "source": [
    "### You previously generated an image of a photoframe with an elephant in a beautifull landscape using imae conditioning canny edge. Now, you want to enhance the image of the photoframe \n",
    "### within the photoframe placed on a wooden table. Next to the frame is a beautiful flower vase, holding a vibrant bouquet of fresh flowers.\n",
    "### The original image is located at data/generated_image/generated_image_conditioning.png.\n",
    "### To achieve this, you will use the image conditioning segmentation technique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fc1007-fb92-4232-aebc-e85f437e08cc",
   "metadata": {},
   "source": [
    "### Image Conditioning prompt for segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31da41ba-18d1-471a-8f0b-863c397db0a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"A photo frame featuring an elegant image of an elephant, placed on a wooden table. Next to the frame is a beautiful flower vase, holding a vibrant bouquet of fresh flowers. The setting is cozy, with soft natural lighting that enhances the intricate details of the elephant artwork and the delicate flowers in the vase. The overall ambiance is serene and artistic, creating a perfect balance between nature and artistry.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e36d52-a1bc-4658-b845-4e258abc5350",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_conditioning_source_image = \"data/generated_image/generated_image_conditioning.png\"\n",
    "image_conditioning_target_image = \"data/generated_image/generated_image_conditioning_refined.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dd2d9e-a308-40da-a375-e5af20a9f2d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "conditioning_source_encoded_image = encode_image(image_conditioning_source_image)\n",
    "\n",
    "# Generate image condition on reference image\n",
    "body = json.dumps(\n",
    "    {\n",
    "        \"taskType\": \"TEXT_IMAGE\",\n",
    "        \"textToImageParams\": {\n",
    "            \"text\": prompt,  # Required\n",
    "            \"conditionImage\": conditioning_source_encoded_image, # Optional\n",
    "            \"controlMode\": \"SEGMENTATION\", # Optional: CANNY_EDGE | SEGMENTATION\n",
    "            \"controlStrength\": 0.6,  # Range: 0.2 to 1.0,\n",
    "        },\n",
    "        \"imageGenerationConfig\": {\n",
    "                \"numberOfImages\": 1,\n",
    "                \"seed\": 42,\n",
    "            }\n",
    "        \n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bdad9e-52c2-4c8f-96c5-4bdcba0bc9b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "generated_image_b64 = invoke_bedrock_model(boto3_bedrock_runtime_client, body, amazon_titan_image_model_id )\n",
    "decode_image(generated_image_b64, image_conditioning_target_image)\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "images = [ image_conditioning_source_image , image_conditioning_target_image ]\n",
    "headings =[ \"Source Image\" ,  \"Generated Image\" ]\n",
    "plot_multiple_images(images, headings, cols=2)\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07002c0f-0e2a-465d-856f-5c051cb84dcd",
   "metadata": {},
   "source": [
    "# Section 6: Color Conditioning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a3d5e6-93cd-4281-b2d4-44d87416b9f3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### You previously generated an image of a photoframe with an elephant in a beautifull landscape using imae conditioning segmentation. Now, you want to enhance the image of the photoframe \n",
    "### within the photoframe placed on a wooden table. Next to the frame is a beautiful flower vase, holding a vibrant bouquet of fresh flowers with a specific color coding like hex_color_code = ['#FF9900', '#232F3E', '#F2F2F2', '#000000', '#146EB4']\n",
    "### The original image is located at data/generated_image/generated_image_conditioning.png.\n",
    "### To achieve this, you will use the colour conditioning technique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e3a6bc-0715-4cce-af09-c71d87638020",
   "metadata": {},
   "source": [
    "### Colour Conditioning prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddfec30-1d45-4011-a672-07ccb5ea6b72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"A photo frame featuring of a original elephant, placed on a wooden table. Next to the frame is a beautiful flower vase. elephant is side wise.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16095f4-58a8-4236-b903-7687c6f93739",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "color_conditioning_source_image = \"data/generated_image/generated_image_conditioning.png\"\n",
    "color_conditioning_target_image = \"data/generated_image/generated_color_conditioning.png\"\n",
    "\n",
    "hex_color_code = ['#FF9900', '#232F3E', '#F2F2F2', '#000000', '#146EB4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9316ce-c8af-48db-8843-a7c8531b0e00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "conditioning_source_encoded_image = encode_image(color_conditioning_source_image)\n",
    "    \n",
    "    \n",
    "# Generate image condition on color palette\n",
    "body = json.dumps({\n",
    "    \"taskType\": \"COLOR_GUIDED_GENERATION\",\n",
    "    \"colorGuidedGenerationParams\": {\n",
    "        \"text\": prompt,\n",
    "        \"colors\": hex_color_code,\n",
    "        \"referenceImage\": conditioning_source_encoded_image,\n",
    "    },\n",
    "    \"imageGenerationConfig\": {\n",
    "        \"numberOfImages\": 1,\n",
    "        \"seed\": 42,\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cec4a6-a8c2-4b18-9ada-ee4b8634d5c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt; plt.figure(figsize=(8, 2)); [plt.gca().add_patch(plt.Rectangle((i, 0), 1, 1, color=c)) or plt.text(i + 0.5, -0.5, c, ha='center', va='center', fontsize=10) for i, c in enumerate(['#FF9900', '#232F3E', '#F2F2F2', '#000000', '#146EB4'])]; plt.xlim(0, 5); plt.ylim(-1, 1); plt.axis('off'); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3369a1f5-d5e3-451a-aa16-02356ebdd4c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "generated_image_b64 = invoke_bedrock_model(boto3_bedrock_runtime_client, body, amazon_titan_image_model_id )\n",
    "decode_image(generated_image_b64, color_conditioning_target_image)\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "images = [ color_conditioning_source_image , color_conditioning_target_image ]\n",
    "headings =[ \"Source Image\" ,  \"Generated Image\" ]\n",
    "plot_multiple_images(images, headings, cols=2)\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d819981e-3198-47b8-b82b-fe5e496e49de",
   "metadata": {},
   "source": [
    "# Section 7: Image Outpainting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5b0481-9e06-4dec-aebe-f48d514dfb32",
   "metadata": {},
   "source": [
    "### You previously generated an image of a photoframe with an elephant in a beautifull landscape using color conditioning. Now, you want to enhance the image of the photoframe \n",
    "### hanging on the wall.\n",
    "### The original image is located at data/generated_image/generated_color_conditioning.png.\n",
    "### To achieve this, you will use the cimge outpainting technique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4b3b27-c7b8-4a0c-8541-6b58eaf0805a",
   "metadata": {},
   "source": [
    "### Image Outpainting prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d081d393-d81e-4045-895c-5a375270011c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the prompt and reference image\n",
    "prompt = \"A big white wall in the background, the elephant photo frame is on the wall.\"\n",
    "mask_prompt = \"elephant photo frame\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0aa463-7e81-475b-865c-01f8308b59a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_outpainting_source_image = \"data/generated_image/generated_color_conditioning.png\"\n",
    "image_outpainting_target_image = \"data/generated_image/generated_image_outpainting.png\"\n",
    "\n",
    "# Expansion setting\n",
    "target_width = 1024\n",
    "target_height = 1024\n",
    "horizontal_position_percent=0.3\n",
    "vertical_position_percent=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa63040-dee0-4cdd-bed4-6f6f94bdd357",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Load reference image\n",
    "original_image = Image.open(image_outpainting_source_image)\n",
    "original_width, original_height = original_image.size\n",
    "\n",
    "# Calculate the position of the original image on the expanded canvas.\n",
    "position = (\n",
    "    int((target_width - original_width * 0.5 ) * horizontal_position_percent),\n",
    "    int((target_height - original_height * 0.5 ) * vertical_position_percent),\n",
    ")\n",
    "\n",
    "# Create an input image which contains the original image with an expanded\n",
    "# canvas.\n",
    "input_image = Image.new(\"RGB\", (target_width, target_height), (235, 235, 235))\n",
    "input_image.paste(original_image, position)\n",
    "input_image.save(image_outpainting_target_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0914741d-f9ca-4b04-80f7-3b81cd280975",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "outpainting_source_encoded_image = encode_image(image_outpainting_source_image)\n",
    "\n",
    "    \n",
    "# Generate image condition on reference image\n",
    "body = json.dumps(\n",
    "    {\n",
    "        \"taskType\": \"OUTPAINTING\",\n",
    "        \"outPaintingParams\": {\n",
    "            \"text\": prompt,  # Required\n",
    "            \"image\": outpainting_source_encoded_image,  # Required\n",
    "            \"maskPrompt\": mask_prompt,  # One of \"maskImage\" or \"maskPrompt\" is required\n",
    "            \"outPaintingMode\": \"PRECISE\",  # One of \"PRECISE\" or \"DEFAULT\"\n",
    "        },\n",
    "        \"imageGenerationConfig\": {\n",
    "                \"numberOfImages\": 1,\n",
    "                \"seed\": 42,\n",
    "            }\n",
    "        \n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8112c54-3942-4e0a-b4bb-718e2c06e647",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "generated_image_b64 = invoke_bedrock_model(boto3_bedrock_runtime_client, body, amazon_titan_image_model_id )\n",
    "decode_image(generated_image_b64, image_outpainting_target_image)\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "images = [ image_outpainting_source_image , image_outpainting_target_image ]\n",
    "headings =[ \"Source Image\" ,  \"Generated Image\" ]\n",
    "plot_multiple_images(images, headings, cols=2)\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bebcfe-c8b3-46e0-982c-ba48ea8cfc78",
   "metadata": {},
   "source": [
    "# Section 8: Background removal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79be8f42-bde7-4f34-a4cf-a925a6860318",
   "metadata": {},
   "source": [
    "### You previously generated an image of an elephant in a beautifull landscape using a prompt. Now, you want to remove the background from the main object (elephant) and generate image of only the elephant.\n",
    "### The original image is located at data/generated_image/generated_image_5.png.\n",
    "### To achieve this, you will use the background removal technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562e8c2b-bc39-4503-94c3-cdbcd9c8b0f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_bckground_removal_source_image = \"data/generated_image/generated_image_5.png\"\n",
    "image_bckground_removal_target_image = \"data/generated_image/generated_image_background_removal.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654eb39f-a37d-44b3-bf6b-107a36610612",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "image_bckground_removal_source_encoded_image = encode_image(image_bckground_removal_source_image)\n",
    "\n",
    "body = json.dumps({\n",
    "    \"taskType\": \"BACKGROUND_REMOVAL\",\n",
    "    \"backgroundRemovalParams\": {\n",
    "        \"image\": image_bckground_removal_source_encoded_image,\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb5d6f7-fce7-4334-bbe1-c13c08e93b22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "generated_image_b64 = invoke_bedrock_model(boto3_bedrock_runtime_client, body, amazon_titan_image_model_id )\n",
    "decode_image(generated_image_b64, image_bckground_removal_target_image)\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "images = [ image_bckground_removal_source_image , image_bckground_removal_target_image ]\n",
    "headings =[ \"Source Image\" ,  \"Generated Image\" ]\n",
    "plot_multiple_images(images, headings, cols=2)\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf680684-2395-4b8c-9680-ad8f44fc87c7",
   "metadata": {},
   "source": [
    "# Section 9: Combination of Text and Image\n",
    "\n",
    "### You want to interpret one image with text. For example, there is a image of a shape. You want to understand the type of shape with the text on the image.\n",
    "### Even, you have an AWS architecture. You want to understand the architecture leveraging generative AI. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ce5937-3964-46f0-9f56-12c2bda09fae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "filename = [ \"rectangle_image_dimention.png\" , \"aws_architecture_glue_dq_pipeline.png\" ]\n",
    "images = [ filename[0] , filename[1] ]\n",
    "headings =[ \"1. Rectangle Image\" ,  \"2. AWS Architecture Image\" ]\n",
    "print(\"\\n\\n\")\n",
    "plot_multiple_images(images, headings, cols=2)\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab85123-9c71-4397-b459-605dc15979ed",
   "metadata": {},
   "source": [
    "\n",
    "#### The code defines a function generate_message to interact with the AWS Bedrock runtime client for invoking an AI model using specified parameters such as model ID, messages, maximum tokens, temperature, and top-p sampling. It prepares the request in JSON format, invokes the model, and parses the response. In the main execution, it processes a list of image files by encoding each image as base64, passing it to the model as a message, and printing the generated response. Images are displayed using IPython's Image display functionality.\n",
    "\n",
    "#### Source of aws_architecture_glue_dq_pipeline.png is https://aws.amazon.com/blogs/big-data/set-up-alerts-and-orchestrate-data-quality-rules-with-aws-glue-data-quality/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f10e5c-921b-4d61-858c-adfa99760052",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def generate_message(boto3_bedrock_runtime_client, model_id, messages, max_tokens=512, top_p=1, temp=0.5, system=''):\n",
    "    \"\"\"\n",
    "    Generate a message using the Bedrock runtime client.\n",
    "    \n",
    "    Args:\n",
    "        boto3_bedrock_runtime_client: Boto3 Bedrock runtime client.\n",
    "        model_id (str): Model ID to invoke.\n",
    "        messages (list): List of messages to pass to the model.\n",
    "        max_tokens (int): Maximum tokens for response.\n",
    "        top_p (float): Top P sampling parameter.\n",
    "        temp (float): Temperature for sampling.\n",
    "        system (str): Optional system-level instructions.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Parsed response body from the model invocation.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Prepare the request body\n",
    "        body = json.dumps({\n",
    "            \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "            \"max_tokens\": max_tokens,\n",
    "            \"messages\": messages,\n",
    "            \"temperature\": temp,\n",
    "            \"top_p\": top_p,\n",
    "            \"system\": system\n",
    "        })\n",
    "\n",
    "        # Invoke the model\n",
    "        response = boto3_bedrock_runtime_client.invoke_model(body=body, modelId=model_id)\n",
    "        response_body = json.loads(response.get('body').read())\n",
    "        return response_body\n",
    "\n",
    "    except botocore.exceptions.ClientError as e:\n",
    "        print(f\"Client error occurred: {e}\")\n",
    "        raise\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Failed to parse JSON response: {e}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        raise\n",
    "\n",
    "# Main execution\n",
    "try:\n",
    "    \n",
    "    for file in filename:\n",
    "        # Define the message list\n",
    "        message_list = [\n",
    "            {\n",
    "                \"role\": 'user',\n",
    "                \"content\": [\n",
    "                    {\"type\": \"image\", \"source\": {\"type\": \"base64\", \"media_type\": \"image/png\", \"data\": encode_image(file)}},\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        # Generate the response\n",
    "        response = generate_message(\n",
    "            boto3_bedrock_runtime_client=boto3_bedrock_runtime_client,\n",
    "            model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\",\n",
    "            messages=message_list,\n",
    "            max_tokens=512,\n",
    "            temp=0.5,\n",
    "            top_p=0.9\n",
    "        )\n",
    "        \n",
    "        from IPython.display import Image as IPImage\n",
    "\n",
    "        print(f\"Image of: {file}\")\n",
    "        print(\"\\n\\n\")\n",
    "        display(IPImage(file))\n",
    "        print(\"\\n\\n\")\n",
    "        # Print the response text\n",
    "        print(response['content'][0]['text'])\n",
    "        print(\"\\n\\n\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during the main execution: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72971cda-4919-4042-93fc-71edd3185140",
   "metadata": {},
   "source": [
    "# End of NoteBook \n",
    "\n",
    "#### <ins>Step 1</ins> \n",
    "\n",
    "##### Please ensure that you close the kernel after using this notebook to avoid any potential charges to your account.\n",
    "\n",
    "##### Process: Go to \"Kernel\" at top option. Choose \"Shut Down Kernel\". \n",
    "##### Refer https://docs.aws.amazon.com/sagemaker/latest/dg/studio-ui.html"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
