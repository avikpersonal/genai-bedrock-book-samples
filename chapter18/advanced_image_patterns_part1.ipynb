{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ed3a60a-5001-46ff-ae70-61d861a00c53",
   "metadata": {
    "tags": []
   },
   "source": [
    "# File Name: advanced_image_patterns_part1.ipynb\n",
    "### Location: Chapter 18\n",
    "### Purpose: \n",
    "#####       1. Perfecting Prompt for Image\n",
    "#####       2. Image Embedding\n",
    "#####       3. Image to Image\n",
    "##### Dependency: simple-sageMaker-bedrock.ipynb at Chapter 3 should work properly.\n",
    "# <ins>-----------------------------------------------------------------------------------</ins>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99464e3-0679-4a67-bb38-8d96892eefa5",
   "metadata": {},
   "source": [
    "# <ins>Amazon SageMaker Classic</ins>\n",
    "#### Those who are new to Amazon SageMaker Classic. Follow the link for the details. https://docs.aws.amazon.com/sagemaker/latest/dg/studio.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91003ca1-0026-46eb-bd09-81861135cb22",
   "metadata": {},
   "source": [
    "# <ins>Environment setup of Kernel</ins>\n",
    "##### Fill \"Image\" as \"Data Science\"\n",
    "##### Fill \"Kernel\" as \"Python 3\"\n",
    "##### Fill \"Instance type\" as \"ml-t3-medium\"\n",
    "##### Fill \"Start-up script\" as \"No Scripts\"\n",
    "##### Click \"Select\"\n",
    "\n",
    "###### Refer https://docs.aws.amazon.com/sagemaker/latest/dg/notebooks-create-open.html for details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c865b7f5-755a-498c-bff6-7647281b15b9",
   "metadata": {},
   "source": [
    "# <ins>Mandatory installation on the kernel through pip</ins>\n",
    "\n",
    "##### This lab will work with below software version. But, if you are trying with latest version of boto3, awscli, and botocore. This code may fail. You might need to change the corresponding api. \n",
    "\n",
    "##### You will see pip dependency errors. you can safely ignore these errors and continue executing rest of the cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ade0112-a4be-4ce8-be92-8cbf28b2acfa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "%pip install --no-build-isolation --force-reinstall -q \\\n",
    "    \"boto3\" \\\n",
    "    \"awscli\" \\\n",
    "    \"botocore\" \\\n",
    "    \"utils\" \\\n",
    "    \"matplotlib\" \\\n",
    "    \"sagemaker\" \\\n",
    "    \"numpy<2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4e3b85-4e64-42ef-9355-ed2a61c68b23",
   "metadata": {},
   "source": [
    "# <ins>Disclaimer</ins>\n",
    "\n",
    "##### You will see pip dependency errors. you can safely ignore these errors and continue executing rest of the cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88ee934-e99c-49ce-9e94-27ffc5baabe1",
   "metadata": {},
   "source": [
    "# <ins>Restart the kernel</ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaf41bf-d2d2-46fa-b1d4-1dd19c45a069",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# restart kernel\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5af76d-b2a9-4740-b8bf-134932804719",
   "metadata": {},
   "source": [
    "# <ins>Python package import</ins>\n",
    "\n",
    "##### boto3 offers various clients for Amazon Bedrock to execute various actions.\n",
    "##### botocore is a low-level interface to AWS tools, while boto3 is built on top of botocore and provides additional features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7268959-6ef0-4cbd-bd53-3b31369b4513",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import io\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import boto3\n",
    "from PIL import Image\n",
    "import botocore\n",
    "import warnings\n",
    "import sagemaker\n",
    "import base64\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d1b877-deab-4961-a249-7663e812fbb8",
   "metadata": {},
   "source": [
    "### Ignore warning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71587271-9f02-46dc-9eaf-5a5291132f8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a707d91-23c2-4786-bd2a-6287ca51ef82",
   "metadata": {},
   "source": [
    "## Define important environment variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4247b5-5fe7-4ec8-9f25-bff782734606",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "# Try-except block to handle potential errors during execution\n",
    "try:\n",
    "    # Create a new Boto3 session to interact with AWS services\n",
    "    # This session manages credentials and region configuration for AWS interactions\n",
    "    boto3_session = boto3.session.Session()\n",
    "\n",
    "    # Retrieve the current AWS region from the session (e.g., 'us-east-1', 'us-west-2')\n",
    "    aws_region_name = boto3_session.region_name\n",
    "\n",
    "    # Initialize Bedrock and Bedrock Runtime clients using Boto3\n",
    "    # These clients enable interactions with AWS Bedrock-related services\n",
    "    boto3_bedrock_client = boto3.client('bedrock', region_name=aws_region_name)\n",
    "    boto3_bedrock_runtime_client = boto3.client('bedrock-runtime', region_name=aws_region_name)\n",
    "\n",
    "    # Create a SageMaker session and retrieve the execution role ARN\n",
    "    # The role ARN authorizes SageMaker to perform tasks on behalf of the user\n",
    "    sagemaker_role_arn = sagemaker.get_execution_role()\n",
    "\n",
    "    # Specify the Amazon Titan image generator model ID for multimodal processing\n",
    "    amazon_titan_image_model_id = \"amazon.titan-image-generator-v2:0\"\n",
    "\n",
    "    # Specify the Amazon Titan embedding model ID for multimodal indexing\n",
    "    multimodal_embed_model_id = \"amazon.titan-embed-image-v1\"\n",
    "\n",
    "    # Store all relevant variables in a dictionary for easier access and management\n",
    "    variables_store = {\n",
    "        \"aws_region_name\": aws_region_name,                           # AWS region name\n",
    "        \"boto3_bedrock_client\": boto3_bedrock_client,                 # Bedrock client instance\n",
    "        \"boto3_bedrock_runtime_client\": boto3_bedrock_runtime_client, # Bedrock Runtime client instance\n",
    "        \"boto3_session\": boto3_session,                               # Current Boto3 session object\n",
    "        \"sagemaker_role_arn\": sagemaker_role_arn,                     # SageMaker execution role ARN\n",
    "        \"multimodal_embed_model_id\": multimodal_embed_model_id,       # Titan embedding model ID\n",
    "        \"amazon_titan_image_model_id\": amazon_titan_image_model_id    # Titan image generator model ID\n",
    "    }\n",
    "\n",
    "    # Print all stored variables for debugging and verification\n",
    "    for var_name, value in variables_store.items():\n",
    "        print(f\"{var_name}: {value}\")\n",
    "\n",
    "# Handle any exceptions that occur during the execution\n",
    "except Exception as e:\n",
    "    # Print an error message if an unexpected error occurs\n",
    "    print(f\"An unexpected error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae0a7d5-a0d5-4071-99e9-e5c50565f743",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Text-to-Image Generation with Amazon Bedrock: Payload Creation and Model Invocation\n",
    "\n",
    "    The provided code consists of two functions that work together to generate images using a text-to-image model in Amazon Bedrock. The create_text_to_image_payload function constructs a JSON payload that includes configuration details such as the prompt for the image, the number of images to generate, image quality, dimensions, CFG scale, and seed for reproducibility. It prepares this data to be used in an InvokeModel request to the Amazon Bedrock service. The invoke_text_to_image_model function sends this payload to the Bedrock model using the invoke_model method of the Boto3 runtime client. It processes the response, which contains the generated image data, and returns it as a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e7cfc4-2999-4c7e-8f02-2e961dc27275",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "def create_text_to_image_payload(prompt, encoded_image=None, negative_prompts=None, num_images=1, quality=\"standard\", \n",
    "                                  height=1024, width=1024, cfg_scale=7.5, seed=42):\n",
    "    \"\"\"\n",
    "    Create the payload for the text-to-image Bedrock model invocation.\n",
    "\n",
    "    This function constructs the JSON payload required for making an InvokeModel request to Amazon Bedrock\n",
    "    to generate images based on a text prompt. When making an InvokeModel request, the body field is populated\n",
    "    with a JSON object that specifies the task type (in this case, \"TEXT_IMAGE\") and various configuration parameters.\n",
    "    The Amazon Titan models support the following parameters:\n",
    "    \n",
    "    - cfgScale: Controls how much the final image reflects the input prompt. A higher value means the image\n",
    "      will more closely align with the prompt.\n",
    "    - seed: A numeric value used to initialize the image generation process. The same seed, when used with the\n",
    "      same prompt and settings, will produce identical results.\n",
    "    - numberOfImages: Defines how many images the model should generate, ranging from 1 to 5.\n",
    "    - quality: Specifies the quality of the output image. You can choose either \"standard\" or \"premium\".\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): The main prompt that describes the image to be generated.\n",
    "        negative_prompts (str): Optional negative prompts that help exclude certain features from the generated image.\n",
    "        num_images (int): The number of images to generate, which can be between 1 and 5.\n",
    "        quality (str): The quality of the generated image. It can either be \"standard\" or \"premium\".\n",
    "        height (int): The height of the image in pixels (default is 1024).\n",
    "        width (int): The width of the image in pixels (default is 1024).\n",
    "        cfg_scale (float): The CFG scale value determines how closely the generated image matches the prompt. \n",
    "                            It ranges from 1.0 (exclusive) to 10.0 (default is 7.5).\n",
    "        seed (int): A seed number to initialize the generation process. The same seed with the same prompt and settings \n",
    "                    will always produce the same image (default is 42).\n",
    "\n",
    "    Returns:\n",
    "        str: A JSON string containing the constructed payload to be sent in the InvokeModel request.\n",
    "    \"\"\"\n",
    "    \n",
    "    if encoded_image == \"\":\n",
    "        # Create the payload dynamically based on whether negative_prompts is provided or not\n",
    "        payload = {\n",
    "            \"taskType\": \"TEXT_IMAGE\",  # Specifies the task type: text-to-image generation.\n",
    "            \"textToImageParams\": {\n",
    "                \"text\": prompt,  # The main prompt that describes the image to be generated (Required).\n",
    "                **({\"negativeText\": negative_prompts} if negative_prompts else {})  # Add negativeText only if it's provided.\n",
    "            },\n",
    "            \"imageGenerationConfig\": {\n",
    "                \"numberOfImages\": num_images,  # The number of images to generate (1 to 5).\n",
    "                \"quality\": quality,  # Image quality: 'standard' or 'premium'.\n",
    "                \"height\": height,  # Image height in pixels.\n",
    "                \"width\": width,  # Image width in pixels.\n",
    "                \"cfgScale\": cfg_scale,  # CFG scale (1.0 exclusive to 10.0, higher values create more prompt alignment).\n",
    "                \"seed\": seed  # Seed for reproducibility of results (same seed gives the same image).\n",
    "            }\n",
    "        }\n",
    "    else:\n",
    "        payload = {\n",
    "            \"taskType\": \"IMAGE_VARIATION\",  # Specifies the task type: text-to-image generation.\n",
    "            \"imageVariationParams\":{\n",
    "                \"text\": prompt,  # The main prompt that describes the image to be generated (Required).\n",
    "                \"images\":[encoded_image],\n",
    "                **({\"negativeText\": negative_prompts} if negative_prompts else {})  # Add negativeText only if it's provided.\n",
    "            },\n",
    "            \"imageGenerationConfig\": {\n",
    "                \"numberOfImages\": num_images,  # The number of images to generate (1 to 5).\n",
    "                \"quality\": quality,  # Image quality: 'standard' or 'premium'.\n",
    "                \"height\": height,  # Image height in pixels.\n",
    "                \"width\": width,  # Image width in pixels.\n",
    "                \"cfgScale\": cfg_scale,  # CFG scale (1.0 exclusive to 10.0, higher values create more prompt alignment).\n",
    "                \"seed\": seed  # Seed for reproducibility of results (same seed gives the same image).\n",
    "            }\n",
    "        }\n",
    "       \n",
    "    return json.dumps(payload)\n",
    "\n",
    "\n",
    "def invoke_text_to_image_model(runtime_client, model_id, payload):\n",
    "    \"\"\"\n",
    "    Invoke the Bedrock text-to-image model.\n",
    "\n",
    "    This function sends the constructed JSON payload to the Amazon Bedrock service to generate images.\n",
    "    The payload contains the prompt and configuration details, and the request is processed by the \n",
    "    specified model (model_id). The response is parsed and returned as a dictionary.\n",
    "    \n",
    "    Args:\n",
    "        runtime_client (boto3.client): The Boto3 Bedrock runtime client for invoking the model.\n",
    "        model_id (str): The identifier for the Bedrock model to be used for text-to-image generation.\n",
    "        payload (str): The JSON string containing the request payload that includes prompt and configuration.\n",
    "\n",
    "    Returns:\n",
    "        dict: The parsed response from the Bedrock model, containing the generated image data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Making the request to invoke the model with the provided payload\n",
    "        response = runtime_client.invoke_model(\n",
    "            body=payload,  # The payload for the model invocation.\n",
    "            modelId=model_id,  # Model ID for the text-to-image generation.\n",
    "            accept=\"application/json\",  # Expected response format.\n",
    "            contentType=\"application/json\"  # The content type for the request body.\n",
    "        )\n",
    "        # Parsing the JSON response body and returning it as a dictionary\n",
    "        return json.loads(response.get(\"body\").read())\n",
    "    except Exception as e:\n",
    "        print(f\"Error invoking text-to-image model: {e}\")  # Handling any errors during invocation\n",
    "        raise  # Raising the exception for further handling if necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1fa5f9-f1d4-4edf-bb9b-3cae42b07243",
   "metadata": {},
   "source": [
    "# Display Base64-encoded Image Using Matplotlib in Headless Environments\n",
    "\n",
    "    The function display_base64_image is designed to display an image that is encoded in Base64 format, making it suitable for use in headless environments. It decodes the Base64 string into image data, loads the image using the Python Imaging Library (PIL), and then displays the image using matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100e1f15-5cce-4d49-9a7f-11ef436d2928",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "def display_base64_image(image_b64, image_number):\n",
    "    \"\"\"\n",
    "    Display a Base64-encoded image using matplotlib (works in headless environments).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Decode the Base64 string\n",
    "        image_data = base64.b64decode(image_b64)\n",
    "        \n",
    "        # Open the image using PIL\n",
    "        image = Image.open(io.BytesIO(image_data))\n",
    "        \n",
    "        # Display the image using matplotlib\n",
    "        plt.imshow(image)\n",
    "        plt.axis('off')  # Hide axis\n",
    "        plt.show()\n",
    "        \n",
    "        save_path = \"data/generated_image\"\n",
    "        os.makedirs(save_path, exist_ok=True)  # Create folder if it doesn't exist\n",
    "        \n",
    "        image_file_name = os.path.join(save_path, f\"generated_image_{image_number}.png\")\n",
    "        image.save(image_file_name)\n",
    "        print(f\"Image saved at: {image_file_name}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error displaying the Base64 image: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589a7839-8e4d-403e-a1f8-49c8f9d405f8",
   "metadata": {},
   "source": [
    "# Generate and Display Image Using Amazon Bedrock Text-to-Image Model\n",
    "\n",
    "    The function image_invoke_model is designed to generate an image based on a given prompt and optional negative prompts using an Amazon Bedrock text-to-image model. It first constructs the necessary payload with parameters like prompt, negative prompts, image dimensions, and configuration settings. Then, it invokes the model via the invoke_text_to_image_model function and processes the response to retrieve the generated image in Base64 format. The function prints a preview of the image's Base64 string, displays the image, and optionally allows for further processing or saving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dafaef-9050-4814-a220-fa29deb64a56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "def image_invoke_model( prompt, image_number, encoded_image, negative_prompts = None):\n",
    "    try:\n",
    "        # Create payload\n",
    "        \n",
    "        payload = create_text_to_image_payload(\n",
    "            prompt=prompt,\n",
    "            negative_prompts=negative_prompts,\n",
    "            num_images=1,\n",
    "            quality=\"standard\",\n",
    "            height=1024,\n",
    "            width=1024,\n",
    "            cfg_scale=7.5,\n",
    "            seed=42,\n",
    "            encoded_image = encoded_image\n",
    "        )\n",
    "\n",
    "        # Invoke model\n",
    "        print(\"Invoking Bedrock text-to-image model...\")\n",
    "        response = invoke_text_to_image_model(boto3_bedrock_runtime_client, amazon_titan_image_model_id, payload)\n",
    "\n",
    "        # Process response\n",
    "        image_b64_format = response[\"images\"][0]\n",
    "        print(f\"Generated image (Base64 preview): {image_b64_format[0:80]}...\")\n",
    "\n",
    "        #display image\n",
    "        display_base64_image(image_b64_format, image_number)\n",
    "\n",
    "    # Optionally save or process the image further\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred in the main execution: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d3519e-6148-4fa0-8838-f124de2de7c4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Section 1: Perfecting Prompt for Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87477ce8-39e8-4600-8d2b-773fd7bd6d46",
   "metadata": {},
   "source": [
    "#### The detail explaination on the \"Perfecting Prompt for Image\" sub section of 18.6 section\n",
    "\n",
    "#### All the prompt and negative prompt example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ef979d-361d-463b-89d2-ee9ad9bf840e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# JSON data with an additional \"image_number\" field\n",
    "sample_test_json_data = [\n",
    "    {\n",
    "        \"image_number\": 1,\n",
    "        \"type\": \"Type of Image\",\n",
    "        \"sub_type\": \"Photograph\",\n",
    "        \"prompt\": \"A clear photograph of a calm lake surrounded by pine trees during sunset, with vibrant orange and pink hues in the sky.\",\n",
    "        \"negative_prompt\": \"\"\n",
    "    },\n",
    "    {\n",
    "        \"image_number\": 2,\n",
    "        \"type\": \"Type of Image\",\n",
    "        \"sub_type\": \"Sketch\",\n",
    "        \"prompt\": \"A pencil sketch of a cozy cottage with a chimney, nestled in a snowy forest, detailed with shading to create depth.\",\n",
    "        \"negative_prompt\": \"\"\n",
    "    },\n",
    "    {\n",
    "        \"image_number\": 3,\n",
    "        \"type\": \"Type of Image\",\n",
    "        \"sub_type\": \"Painting\",\n",
    "        \"prompt\": \"An oil painting of a vibrant sunflower field under a bright blue sky, inspired by Van Gogh's expressive brushstrokes.\",\n",
    "        \"negative_prompt\": \"\"\n",
    "    },\n",
    "    {\n",
    "        \"image_number\": 4,\n",
    "        \"type\": \"Type of Image\",\n",
    "        \"sub_type\": \"Digital Art\",\n",
    "        \"prompt\": \"A digital artwork of a futuristic city with flying cars zipping past towering skyscrapers, illuminated by glowing holographic billboards.\",\n",
    "        \"negative_prompt\": \"\"\n",
    "    },\n",
    "    {\n",
    "        \"image_number\": 5,\n",
    "        \"type\": \"Description\",\n",
    "        \"sub_type\": \"Subject\",\n",
    "        \"prompt\": \"A majestic elephant walking across the African savannah, with the sun setting behind it, casting long shadows.\",\n",
    "        \"negative_prompt\": \"\"\n",
    "    },\n",
    "    {\n",
    "        \"image_number\": 6,\n",
    "        \"type\": \"Description\",\n",
    "        \"sub_type\": \"Object\",\n",
    "        \"prompt\": \"A classic pocket watch with intricate engravings, resting on a velvet cushion.\",\n",
    "        \"negative_prompt\": \"\"\n",
    "    },\n",
    "    {\n",
    "        \"image_number\": 7,\n",
    "        \"type\": \"Description\",\n",
    "        \"sub_type\": \"Environment\",\n",
    "        \"prompt\": \"A tranquil beach at dawn, with soft waves lapping against the shore and a golden glow from the rising sun.\",\n",
    "        \"negative_prompt\": \"\"\n",
    "    },\n",
    "    {\n",
    "        \"image_number\": 8,\n",
    "        \"type\": \"Description\",\n",
    "        \"sub_type\": \"Scene\",\n",
    "        \"prompt\": \"A vibrant carnival scene with colorful tents, performers, and joyful crowds under the bright lights of a summer night.\",\n",
    "        \"negative_prompt\": \"\"\n",
    "    },\n",
    "    {\n",
    "        \"image_number\": 9,\n",
    "        \"type\": \"Style Keywords\",\n",
    "        \"sub_type\": \"Hyper-Realistic\",\n",
    "        \"prompt\": \"A hyper-realistic depiction of a bustling city street during a rainy night, with neon lights reflecting off the wet pavement.\",\n",
    "        \"negative_prompt\": \"\"\n",
    "    },\n",
    "    {\n",
    "        \"image_number\": 10,\n",
    "        \"type\": \"Style Keywords\",\n",
    "        \"sub_type\": \"Artistic (Classical Painting)\",\n",
    "        \"prompt\": \"An impressionist-style painting inspired by Claude Monet, featuring a serene water lily pond with soft, blended brushstrokes.\",\n",
    "        \"negative_prompt\": \"\"\n",
    "    },\n",
    "    {\n",
    "        \"image_number\": 11,\n",
    "        \"type\": \"Style Keywords\",\n",
    "        \"sub_type\": \"Futuristic (Anime Style)\",\n",
    "        \"prompt\": \"A futuristic anime-style cityscape with glowing skyscrapers, flying vehicles, and a vibrant night sky filled with holographic advertisements.\",\n",
    "        \"negative_prompt\": \"\"\n",
    "    },\n",
    "    {\n",
    "        \"image_number\": 12,\n",
    "        \"type\": \"Style Keywords\",\n",
    "        \"sub_type\": \"Fantasy (Digital Art)\",\n",
    "        \"prompt\": \"A fantasy digital art scene of a dragon perched on a cliff, overlooking a glowing enchanted forest under a starlit sky.\",\n",
    "        \"negative_prompt\": \"\"\n",
    "    },\n",
    "    {\n",
    "        \"image_number\": 13,\n",
    "        \"type\": \"Style Keywords\",\n",
    "        \"sub_type\": \"Minimalist\",\n",
    "        \"prompt\": \"A minimalist artwork of a lone tree in a desert, with clean lines and a muted color palette of beige and brown tones.\",\n",
    "        \"negative_prompt\": \"\"\n",
    "    },\n",
    "    {\n",
    "        \"image_number\": 14,\n",
    "        \"type\": \"Style Keywords\",\n",
    "        \"sub_type\": \"Vintage Photography\",\n",
    "        \"prompt\": \"A vintage sepia-toned photograph of a 1920s train station, with steam billowing from locomotives and passengers dressed in period attire.\",\n",
    "        \"negative_prompt\": \"\"\n",
    "    },\n",
    "    {\n",
    "        \"image_number\": 15,\n",
    "        \"type\": \"Adjectives and Details\",\n",
    "        \"sub_type\": \"Lighting\",\n",
    "        \"prompt\": \"A dramatic scene lit by the cool, silvery glow of moonlight reflecting on a tranquil ocean, with soft shadows creating a sense of depth.\",\n",
    "        \"negative_prompt\": \"\"\n",
    "    },\n",
    "    {\n",
    "        \"image_number\": 16,\n",
    "        \"type\": \"Adjectives and Details\",\n",
    "        \"sub_type\": \"Lens Details\",\n",
    "        \"prompt\": \"Captured with a 24mm ultra-wide-angle lens, showcasing the expansive view of a rugged canyon with intricate textures and layers of rock formations.\",\n",
    "        \"negative_prompt\": \"\"\n",
    "    },\n",
    "    {\n",
    "        \"image_number\": 17,\n",
    "        \"type\": \"Adjectives and Details\",\n",
    "        \"sub_type\": \"Framing\",\n",
    "        \"prompt\": \"A close-up shot of a vibrant butterfly resting on a flower, perfectly framed by blurred wildflowers in the background, emphasizing the subject's delicate details.\",\n",
    "        \"negative_prompt\": \"\"\n",
    "    },\n",
    "    {\n",
    "        \"image_number\": 18,\n",
    "        \"type\": \"Negative Prompts\",\n",
    "        \"sub_type\": \"Lighting\",\n",
    "        \"prompt\": \"Golden hour lighting illuminating a tranquil garden.\",\n",
    "        \"negative_prompt\": \"A dark, dimly lit garden with harsh shadows, lacking the warmth of golden hour lighting.\"\n",
    "    },\n",
    "    {\n",
    "        \"image_number\": 19,\n",
    "        \"type\": \"Negative Prompts\",\n",
    "        \"sub_type\": \"Lens Details\",\n",
    "        \"prompt\": \"Captured with an 85mm wide-angle lens for a cinematic effect.\",\n",
    "        \"negative_prompt\": \"Shot with a distorted fisheye lens, causing the image to look warped and unnatural.\"\n",
    "    },\n",
    "    {\n",
    "        \"image_number\": 20,\n",
    "        \"type\": \"Negative Prompts\",\n",
    "        \"sub_type\": \"Framing\",\n",
    "        \"prompt\": \"A close-up portrait of a young woman wearing traditional attire.\",\n",
    "        \"negative_prompt\": \"A distant, full body shot of a person wearing modern casual clothing, with no focus on the face.\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c1d9a5-c0f3-45ed-814a-b19485e28799",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "encoded_image = \"\"\n",
    "# Example: Print the parsed data\n",
    "for item in sample_test_json_data:\n",
    "    \n",
    "    print(\"-------------------------------\\n\\n\")\n",
    "    print(f\"Image Number: {item['image_number']}\")\n",
    "    print(f\"Type: {item['type']}\")\n",
    "    print(f\"Sub Type: {item['sub_type']}\")\n",
    "    print(f\"Prompt: {item['prompt']}\")\n",
    "    \n",
    "    negative_prompt = None if item['negative_prompt'] == \"\" else item['negative_prompt']\n",
    "            \n",
    "    print(f\"Negative Prompt: {negative_prompt}\")\n",
    "    print()\n",
    "    image_invoke_model( item['prompt'] , item['image_number'], encoded_image, negative_prompt ) \n",
    "    print(\"\\n\\n\\n\")\n",
    "    print(\"-------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d36beb7-a705-401a-924c-14da6285c761",
   "metadata": {},
   "source": [
    "# Section 2: Image Embedding "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ffe2a4-bae0-4bc0-af39-1c54e22db06e",
   "metadata": {},
   "source": [
    "### Generate Multimodal Embeddings with Image or Text Inputs\n",
    "\n",
    "    The get_titan_multimodal_embedding function generates multimodal embeddings for input images  using a specified model. It accepts an optional image path and a desired embedding dimension (default is 1024). The function validates the inputs, encodes the image to Base64 if provided, and constructs a payload with the embedding configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52145548-4ebd-4507-a9e8-3085c37f2d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def get_titan_multimodal_embedding(\n",
    "    image_path: str = None,  # Maximum image dimensions: 2048 x 2048 pixels\n",
    "    dimension: int = 1024,  # Desired embedding dimension (default 1024, other options: 384, 256)\n",
    "    model_id: str = multimodal_embed_model_id  # Predefined model ID for the multimodal embedding\n",
    "):\n",
    "    \"\"\"\n",
    "    Function to obtain multimodal embeddings by providing either an image .\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Path to the image file (optional).\n",
    "        dimension (int): The dimensionality of the embedding output (default is 1024).\n",
    "        model_id (str): Model identifier for the multimodal embedding model.\n",
    "    \n",
    "    Returns:\n",
    "        dict: The response from the Bedrock model containing the multimodal embeddings.\n",
    "    \n",
    "    Raises:\n",
    "        FileNotFoundError: If the image file does not exist at the given path.\n",
    "        AssertionError: If neither image is provided.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize the payload to send to the model\n",
    "    payload_body = {}\n",
    "\n",
    "    # Embedding configuration with the specified output dimension\n",
    "    embedding_config = {\n",
    "        \"embeddingConfig\": { \n",
    "            \"outputEmbeddingLength\": dimension\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Process image input if provided\n",
    "    if image_path:\n",
    "        # Check if the provided image path exists locally\n",
    "        if os.path.exists(image_path):\n",
    "            # Open the image file in binary mode and encode it in base64\n",
    "            with open(image_path, \"rb\") as image_file:\n",
    "                encoded_image = base64.b64encode(image_file.read()).decode('utf8')\n",
    "            # Add the base64 encoded image to the payload\n",
    "            payload_body[\"inputImage\"] = encoded_image\n",
    "        else:\n",
    "            # Raise an error if the image file does not exist\n",
    "            raise FileNotFoundError(f\"The image file at {image_path} does not exist.\")\n",
    "    \n",
    "\n",
    "    # Ensure that either image or text is provided for the request\n",
    "    assert payload_body, \"Please provide either an image.\"\n",
    "\n",
    "    try:\n",
    "        # Invoke the model using the Bedrock runtime client to get multimodal embeddings\n",
    "        response = boto3_bedrock_runtime_client.invoke_model(\n",
    "            body=json.dumps({**payload_body, **embedding_config}), \n",
    "            modelId=model_id,\n",
    "            accept=\"application/json\", \n",
    "            contentType=\"application/json\"\n",
    "        )\n",
    "        # Return the parsed JSON response from the model\n",
    "        return json.loads(response.get(\"body\").read())\n",
    "\n",
    "    except Exception as e:\n",
    "        # Handle any exceptions that might occur during the model invocation\n",
    "        print(f\"An error occurred while invoking the model: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1214a83a-9f92-44e9-90b3-da0081a31252",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "print(\"-------------------------------\\n\\n\")\n",
    "print(f\"Example of embedding\")\n",
    "    \n",
    "random_png_file = \"data/generated_image/generated_image_20.png\"\n",
    "\n",
    "print(f\"Randomly selected file: {random_png_file}\\n\")\n",
    "\n",
    "embedding = get_titan_multimodal_embedding(image_path=random_png_file, dimension=1024)\n",
    "\n",
    "print(embedding[\"embedding\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5554ffc3-4bd7-4047-81e5-7ea5c6c398fa",
   "metadata": {},
   "source": [
    "# Section 3: Image to Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead4b378-9034-4994-b4f8-a73d795b60c3",
   "metadata": {},
   "source": [
    "    The image_to_base64 function converts an image file into a Base64 encoded string. It attempts to open the file in binary read mode, encode its contents, and return the encoded string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688cb449-687d-4707-9b74-0f6f7a622bce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def image_to_base64(image_path):\n",
    "    \"\"\"\n",
    "    Converts an image file to its Base64 encoded string representation.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): The path to the image file.\n",
    "\n",
    "    Returns:\n",
    "        str: Base64 encoded string of the image.\n",
    "             Returns None if an error occurs during encoding.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Open the image file in binary read mode\n",
    "        with open(image_path, \"rb\") as image_file:\n",
    "            # Read the file's contents and encode it into Base64 format\n",
    "            encoded_image = base64.b64encode(image_file.read()).decode('utf8')\n",
    "        return encoded_image\n",
    "    except FileNotFoundError:\n",
    "        # Handle the case where the file path is invalid\n",
    "        print(f\"Error: The file '{image_path}' was not found.\")\n",
    "    except Exception as e:\n",
    "        # Handle any other unexpected errors\n",
    "        print(f\"An error occurred: {e}\")\n",
    "    \n",
    "    # Return None if an error occurs\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c8a3bc-2299-4bef-a8b3-08ef461aac0d",
   "metadata": {},
   "source": [
    "#### Example of prompt and negative prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7789b3b-e8ed-4be3-9e13-f6ae0e04db2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "extension_prompt = \"An ancient lighthouse perched on a cliff, its beam piercing through the cool moonlight as the ocean glimmers below.\"\n",
    "negative_prompt = \"Avoid stormy weather, rough seas, modern or futuristic lighthouses, brightly lit surroundings, warm or golden lighting, visible human figures, cluttered landscapes, exaggerated fantasy elements, overly colorful skies, or unrealistic structures.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef68ab3-a199-4bf9-8e74-d5270739525b",
   "metadata": {},
   "source": [
    "### Implementing on top of the image data/generated_image/generated_image_7.png"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b51fb9-9e08-45e4-adf2-517bb7cb4584",
   "metadata": {},
   "source": [
    "##### Encoding a specified image file to Base64 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a53eda-0c05-449e-b800-e62e9c0ba9ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"-------------------------------\")\n",
    "print(f\"Example of Image to Image\")\n",
    "    \n",
    "random_png_file = \"data/generated_image/generated_image_7.png\"\n",
    "\n",
    "print(f\"Randomly selected file: {random_png_file}\")\n",
    "\n",
    "encoded_image = image_to_base64(random_png_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f77376f-d836-44ed-8861-c0147390c237",
   "metadata": {},
   "source": [
    "#### The code measures the execution time of invoking an image generation model with a given extension prompt, negative prompt, and image number, while printing relevant details and displaying the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547f4f49-3308-4b3f-bd66-4bca92323654",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "image_number = 21 \n",
    "# Example: Print the parsed data\n",
    "print(f\"Extension Prompt: {extension_prompt}\")\n",
    "print(f\"Negative Prompt: {negative_prompt}\")\n",
    "print(f\"Image Number: {image_number}\")\n",
    "print()\n",
    "image_invoke_model( extension_prompt , image_number, encoded_image, negative_prompt ) \n",
    "print(\"\\n\\n\\n\")\n",
    "print(\"-------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72971cda-4919-4042-93fc-71edd3185140",
   "metadata": {},
   "source": [
    "# End of NoteBook \n",
    "\n",
    "#### <ins>Step 1</ins> \n",
    "\n",
    "##### Please ensure that you close the kernel after using this notebook to avoid any potential charges to your account.\n",
    "\n",
    "##### Process: Go to \"Kernel\" at top option. Choose \"Shut Down Kernel\". \n",
    "##### Refer https://docs.aws.amazon.com/sagemaker/latest/dg/studio-ui.html"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
