{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ed3a60a-5001-46ff-ae70-61d861a00c53",
   "metadata": {
    "tags": []
   },
   "source": [
    "# File Name: simple_multimodal_knwl_bases_building.ipynb\n",
    "### Location: Chapter 19\n",
    "### Purpose: \n",
    "#####             1. Create collection on serverless opensearch\n",
    "#####             2. Create a network policy for collection\n",
    "#####             3. Create a security policy for encryption using an AWS-owned key\n",
    "#####             4. Create a access policy for collection to define permissions for the collection and index\n",
    "#####             5. Call the create_access_policy method to define permissions for the collection and index\n",
    "#####             6. Create a vector search collection in OpenSearch Serverless\n",
    "#####             7. Collection will take some time to be \"ACTIVE\". So, checking when the collection is \"ACTIVE\" for the next steps\n",
    "#####             8. Index Creation on the collection\n",
    "#####             9. Search capability with a simple text prompts\n",
    "#####             10. Search capability features a combination of text and image prompts\n",
    "\n",
    "##### Dependency: simple_multimodal_data_prep.ipynb at Chapter 19 should work properly.\n",
    "\n",
    "# <ins>-----------------------------------------------------------------------------------</ins>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99464e3-0679-4a67-bb38-8d96892eefa5",
   "metadata": {},
   "source": [
    "# <ins>Amazon SageMaker Classic</ins>\n",
    "#### Those who are new to Amazon SageMaker Classic. Follow the link for the details. https://docs.aws.amazon.com/sagemaker/latest/dg/studio.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91003ca1-0026-46eb-bd09-81861135cb22",
   "metadata": {},
   "source": [
    "# <ins>Environment setup of Kernel</ins>\n",
    "##### Fill \"Image\" as \"Data Science\"\n",
    "##### Fill \"Kernel\" as \"Python 3\"\n",
    "##### Fill \"Instance type\" as \"ml-t3-medium\"\n",
    "##### Fill \"Start-up script\" as \"No Scripts\"\n",
    "##### Click \"Select\"\n",
    "\n",
    "###### Refer https://docs.aws.amazon.com/sagemaker/latest/dg/notebooks-create-open.html for details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c865b7f5-755a-498c-bff6-7647281b15b9",
   "metadata": {},
   "source": [
    "# <ins>Mandatory installation on the kernel through pip</ins>\n",
    "\n",
    "##### This lab will work with below software version. But, if you are trying with latest version of boto3, awscli, and botocore. This code may fail. You might need to change the corresponding api. \n",
    "\n",
    "##### You will see pip dependency errors. you can safely ignore these errors and continue executing rest of the cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ade0112-a4be-4ce8-be92-8cbf28b2acfa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install --no-build-isolation --force-reinstall -q \\\n",
    "    \"boto3>=1.34.84\" \\\n",
    "    \"opensearch-py>=2.7.1\" \\\n",
    "    \"retrying>=1.3.4\" \\\n",
    "    \"ragas\" \\\n",
    "    \"ipywidgets>=7.6.5\" \\\n",
    "    \"iprogress>=0.4\" \\\n",
    "    \"langchain>=0.2.16\" \\\n",
    "    \"langchain_community>=0.2.17\" \\\n",
    "    \"awscli>=1.32.84\" \\\n",
    "    \"botocore>=1.34.84\" \\\n",
    "    \"langchain-aws>=0.1.7\"    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4e3b85-4e64-42ef-9355-ed2a61c68b23",
   "metadata": {},
   "source": [
    "# <ins>Disclaimer</ins>\n",
    "\n",
    "##### You will see pip dependency errors. you can safely ignore these errors and continue executing rest of the cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88ee934-e99c-49ce-9e94-27ffc5baabe1",
   "metadata": {},
   "source": [
    "# <ins>Restart the kernel</ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaf41bf-d2d2-46fa-b1d4-1dd19c45a069",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# restart kernel\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5af76d-b2a9-4740-b8bf-134932804719",
   "metadata": {},
   "source": [
    "# <ins>Python package import</ins>\n",
    "\n",
    "##### boto3 offers various clients for Amazon Bedrock to execute various actions.\n",
    "##### botocore is a low-level interface to AWS tools, while boto3 is built on top of botocore and provides additional features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7268959-6ef0-4cbd-bd53-3b31369b4513",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import boto3\n",
    "import botocore\n",
    "import pprint\n",
    "import random\n",
    "from retrying import retry\n",
    "import warnings\n",
    "import time\n",
    "from opensearchpy import OpenSearch, RequestsHttpConnection, AWSV4SignerAuth, RequestError\n",
    "from botocore.exceptions import NoCredentialsError, PartialCredentialsError\n",
    "import pprint as pp\n",
    "from botocore.exceptions import BotoCoreError, ClientError\n",
    "import pandas as pd\n",
    "import tqdm.notebook as tq\n",
    "from IPython.display import display, Image, HTML\n",
    "import base64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d1b877-deab-4961-a249-7663e812fbb8",
   "metadata": {},
   "source": [
    "### Ignore warning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71587271-9f02-46dc-9eaf-5a5291132f8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f761e72d-9680-4b5d-a9cf-563407118ed3",
   "metadata": {},
   "source": [
    "### Bringing all the store variable value from previous notebook. Here simple_multimodal_data_prep.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ff5991-aaf9-40d9-b906-4adfdc2e232c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b83ea1-9c4e-4ad2-9f83-4dfb0721a166",
   "metadata": {},
   "source": [
    "## Define important environment variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccf36a8-87e3-462a-9a13-4a286861c327",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Try-except block to handle potential errors\n",
    "try:\n",
    "    # Create a new Boto3 session to interact with AWS services\n",
    "    boto3_session_name = boto3.session.Session()\n",
    "\n",
    "\n",
    "    # Create a Bedrock Agent client using the current session and region\n",
    "    bedrock_agent_client = boto3_session_name.client('bedrock-agent', region_name=aws_region_name)\n",
    "    \n",
    "    # Initialize Bedrock and Bedrock Runtime clients using Boto3\n",
    "    # These clients will allow interactions with Bedrock-related AWS services\n",
    "    boto3_bedrock_client = boto3.client('bedrock', region_name=aws_region_name)\n",
    "    boto3_bedrock_runtime_client = boto3.client('bedrock-runtime', region_name=aws_region_name)\n",
    "\n",
    "    # Define the service name for Amazon OpenSearch Serverless (AOSS)\n",
    "    opensearch_service_name = 'aoss'\n",
    "\n",
    "    # Create an S3 client to interact with Amazon S3\n",
    "    s3_client = boto3.client('s3')\n",
    "\n",
    "    # Create an STS client to interact with AWS Security Token Service (STS)\n",
    "    sts_client = boto3.client('sts')\n",
    "\n",
    "    # Get the AWS account ID of the caller\n",
    "    aws_account_id = sts_client.get_caller_identity()[\"Account\"]\n",
    "\n",
    "    # Generate a suffix using the region and account ID for the S3 bucket name\n",
    "    s3_suffix = f\"{aws_region_name}-{aws_account_id}\"\n",
    "\n",
    "    # Define the name of the S3 bucket (you can replace this with your actual bucket name)\n",
    "    s3_bucket_name = f'bedrock-kb-{s3_suffix}'\n",
    "\n",
    "    # PrettyPrinter instance for formatted output\n",
    "    pretty_printer = pprint.PrettyPrinter(indent=2)\n",
    "\n",
    "    # Generate a random suffix number between 200 and 900\n",
    "    random_suffix = random.randrange(200, 900)\n",
    "    \n",
    "\n",
    "    # Create an OpenSearch Serverless (AOSS) client using the current session\n",
    "    aoss_client = boto3_session_name.client('opensearchserverless')\n",
    "\n",
    "    # Generate unique names for the vector store and index based on the suffix\n",
    "    vector_store_name = f'multimodal-sample-rag-{random_suffix}'\n",
    "    index_name = f\"multimodal-sample-rag-index-{random_suffix}\"\n",
    "\n",
    "    # Create an IAM client to interact with Identity and Access Management (IAM) service\n",
    "    iam_client = boto3_session_name.client('iam')\n",
    "\n",
    "    # Retrieve the current AWS account number and ARN of the caller\n",
    "    sts_client = boto3.client('sts')\n",
    "    identity_arn = sts_client.get_caller_identity().get('Arn')\n",
    "    \n",
    "    # Create security policy name for aoss collection\n",
    "    security_policy_name = f'multimodal-col-sec-policy-{random_suffix}'\n",
    "    network_policy_name = f'multimodal-col-net-policy-{random_suffix}'\n",
    "    access_policy_name = f'multimodal-col-acs-policy-{random_suffix}'\n",
    "    \n",
    "    # Embedding model ARN for Bedrock\n",
    "    embeddingModelArn = f\"arn:aws:bedrock:{aws_region_name}::foundation-model/amazon.titan-embed-text-v1\"\n",
    "    \n",
    "    # Amazon Knowledges Bases variable \n",
    "    bedrock_knowledge_bases_name = f\"multimodal-knowl-bases-{random_suffix}\"\n",
    "    description = \"Bedrock multimodal sample knowledge bases.\"\n",
    "\n",
    "    # Store all variables in a dictionary\n",
    "    variables_store = {\n",
    "        \"aws_region_name\": aws_region_name,\n",
    "        \"bedrock_agent_client\": bedrock_agent_client,\n",
    "        \"opensearch_service_name\": opensearch_service_name,\n",
    "        \"s3_client\": s3_client,\n",
    "        \"sts_client\": sts_client,\n",
    "        \"aws_account_id\": aws_account_id,\n",
    "        \"s3_suffix\": s3_suffix,\n",
    "        \"s3_bucket_name\": s3_bucket_name,\n",
    "        \"random_suffix\": random_suffix,\n",
    "        \"aoss_client\": aoss_client,\n",
    "        \"vector_store_name\": vector_store_name,\n",
    "        \"index_name\": index_name,\n",
    "        \"iam_client\": iam_client,\n",
    "        \"sts_client\": sts_client,\n",
    "        \"identity_arn\": identity_arn,\n",
    "        \"security_policy_name\": security_policy_name,\n",
    "        \"network_policy_name\": network_policy_name,\n",
    "        \"access_policy_name\": access_policy_name,\n",
    "        \"embeddingModelArn\": embeddingModelArn,\n",
    "        \"bedrock_knowledge_bases_name\": bedrock_knowledge_bases_name,\n",
    "        \"description\": description\n",
    "    }\n",
    "\n",
    "    # Print all variables\n",
    "    for var_name, value in variables_store.items():\n",
    "        print(f\"{var_name}: {value}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761c5750-9c32-46d0-afdc-6fbd44785b22",
   "metadata": {},
   "source": [
    "### %store magic command to store the variable for use in other notebook cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2ee542-8bb1-47f3-b2ea-a9b907691d60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%store bucket_name aws_region_name opensearch_service_name embeddingModelArn description\n",
    "%store aws_account_id s3_suffix s3_bucket_name random_suffix bedrock_knowledge_bases_name\n",
    "%store vector_store_name index_name identity_arn security_policy_name network_policy_name access_policy_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97b66a5-a3ca-423d-b5ec-024b0b19204a",
   "metadata": {},
   "source": [
    "# Create collection on serverless opensearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6bd77a-6761-4075-b7ee-da9839a3c03b",
   "metadata": {},
   "source": [
    "### Create a network policy for collection\n",
    "\n",
    "##### This code creates a network security policy for an Amazon OpenSearch Serverless (AOSS) collection using the aoss_client from the AWS Boto3 library. The policy is named network_policy_name and specifies access rules in JSON format, targeting a resource identified as collection/<vector_store_name>. The policy type is set to network, with an option (AllowFromPublic) to allow public access, customizable based on the use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af877c24-6b7f-4798-b585-8ce44ec1b47e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Create a network policy for collection\n",
    "\n",
    "try:\n",
    "    # Creating a network security policy\n",
    "    network_policy_name_res = aoss_client.create_security_policy(\n",
    "        name=network_policy_name,  # Name of the security policy\n",
    "        policy=json.dumps(  # JSON-formatted policy rules\n",
    "            [\n",
    "                {\n",
    "                    'Rules': [\n",
    "                        {\n",
    "                            'Resource': ['collection/' + vector_store_name],  # Define the resource\n",
    "                            'ResourceType': 'collection'  # Specify that it's a collection resource\n",
    "                        }\n",
    "                    ],\n",
    "                    'AllowFromPublic': True  # Allow public access (may need to change based on your use case)\n",
    "                }\n",
    "            ]\n",
    "        ),\n",
    "        type='network'  # Define the type of security policy as 'network'\n",
    "    )\n",
    "\n",
    "    # If the security policy is created successfully, print the success message\n",
    "    print(f\"Security policy '{network_policy_name}' created successfully.\")\n",
    "\n",
    "# Handle the case where the security policy already exists\n",
    "except aoss_client.exceptions.ConflictException:\n",
    "    print(f\"Security policy '{network_policy_name}' already exists.\")\n",
    "\n",
    "# Handle validation errors such as incorrect policy structure\n",
    "except aoss_client.exceptions.ValidationException as e:\n",
    "    print(f\"Validation error when creating security policy: {str(e)}\")\n",
    "\n",
    "# Catch any other general exceptions\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while creating the security policy: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969b252f-75f8-446a-8f55-cbaec1b1e48b",
   "metadata": {},
   "source": [
    "### Create a security policy for encryption using an AWS-owned key\n",
    "\n",
    "##### This code snippet creates an encryption security policy for an Amazon OpenSearch Serverless (AOSS) collection using the AWS Boto3 aoss_client. The policy, named security_policy_name, is configured to use an AWS-owned key for encryption (AWSOwnedKey: True). The target resource is specified as collection/<vector_store_name>, ensuring encryption rules apply specifically to the intended collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c9af15-f20b-4a5a-bdc2-5fd2f2ea10c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Create a security policy for encryption using an AWS-owned key\n",
    "\n",
    "try:\n",
    "    security_policy_response = aoss_client.create_security_policy(\n",
    "        name=security_policy_name,\n",
    "        policy=json.dumps(\n",
    "            {\n",
    "                'Rules': [{'Resource': ['collection/' + vector_store_name],\n",
    "                           'ResourceType': 'collection'}],\n",
    "                'AWSOwnedKey': True\n",
    "            }),\n",
    "        type='encryption'\n",
    "    )\n",
    "    \n",
    "    print(f\"Security policy '{security_policy_name}' created successfully.\")\n",
    "except aoss_client.exceptions.ConflictException:\n",
    "    print(f\"Security policy '{security_policy_name}' already exists.\")\n",
    "except aoss_client.exceptions.ValidationException as e:\n",
    "    print(f\"Validation error when creating security policy: {str(e)}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while creating security policy: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56194ff3-d453-42c1-b51f-8fe468b52326",
   "metadata": {},
   "source": [
    "### Create a access policy for collection to define permissions for the collection and index\n",
    "\n",
    "##### This code defines a function, find_iam_role_by_name_substring, to locate an IAM role and retrieve its ARN based on a specified substring within the role name. Using the AWS Boto3 iam_client, it lists all IAM roles and filters them for names containing the substring \"GenAIBookBedrockSageMakerExecutionR\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d2612b-fa71-4215-9bc5-46e73bade035",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Find out IAM role and ARN for this session\n",
    "\n",
    "def find_iam_role_by_name_substring(substring):\n",
    "    try:\n",
    "        # Use list_roles to retrieve IAM roles\n",
    "        response = iam_client.list_roles()\n",
    "\n",
    "        # Filter roles by name that contains the substring\n",
    "        matching_roles = [role for role in response['Roles'] if substring in role['RoleName']]\n",
    "\n",
    "        if matching_roles:\n",
    "            for role in matching_roles:\n",
    "                print(f\"Found Role: {role['RoleName']} | ARN: {role['Arn']}\")\n",
    "                genaibookedbedrocksagemakerexecutionrolearn = role['Arn']\n",
    "        else:\n",
    "            print(f\"No roles found with name containing '{substring}'.\")\n",
    "            \n",
    "        return genaibookedbedrocksagemakerexecutionrolearn\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "\n",
    "# Call the function with the desired substring\n",
    "genaibookedbedrocksagemakerexecutionrolearn = find_iam_role_by_name_substring(\"GenAIBookBedrockSageMakerExecutionR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cce7cf-e986-4638-af2d-349ddef43338",
   "metadata": {},
   "source": [
    "### %store magic command to store the variable for use in other notebook cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbf9842-eae6-455c-997e-f5be98edd657",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%store genaibookedbedrocksagemakerexecutionrolearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b69efa-384d-4b93-a718-aee131e3ae88",
   "metadata": {},
   "source": [
    "### Call the create_access_policy method to define permissions for the collection and index\n",
    "\n",
    "##### This code creates an access policy for managing permissions on an Amazon OpenSearch Serverless (AOSS) collection and index using the AWS Boto3 aoss_client. The policy, named access_policy_name, defines detailed rules for both the collection and index resources, specifying actions allowed for each.\n",
    "##### Policy Rules:\n",
    "#####               a) For collection resources (collection/<vector_store_name>)\n",
    "#####               b) For index resources (index/<vector_store_name>/*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62e54ef-d19b-4e03-ab21-0c3c51f9515e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "try:\n",
    "    \n",
    "    access_policy_res = aoss_client.create_access_policy(\n",
    "        name=access_policy_name,  # The name of the access policy being created\n",
    "        policy=json.dumps(  # The access policy body, provided in JSON format\n",
    "            [\n",
    "                {\n",
    "                    'Rules': [  # Define the access rules for the resources\n",
    "                        {\n",
    "                            'Resource': ['collection/' + vector_store_name],  # Specify the resource collection\n",
    "                            'Permission': [  # Define allowed actions for the collection\n",
    "                                'aoss:CreateCollectionItems',  # Allows creating items in the collection\n",
    "                                'aoss:DeleteCollectionItems',  # Allows deleting items from the collection\n",
    "                                'aoss:UpdateCollectionItems',  # Allows updating items in the collection\n",
    "                                'aoss:DescribeCollectionItems'  # Allows describing items in the collection\n",
    "                            ],\n",
    "                            'ResourceType': 'collection'  # Define resource type as collection\n",
    "                        },\n",
    "                        {\n",
    "                            'Resource': ['index/' + vector_store_name + '/*'],  # Specify the index resource path\n",
    "                            'Permission': [  # Define allowed actions for the index\n",
    "                                'aoss:CreateIndex',  # Allows creating an index\n",
    "                                'aoss:DeleteIndex',  # Allows deleting an index\n",
    "                                'aoss:UpdateIndex',  # Allows updating an index\n",
    "                                'aoss:DescribeIndex',  # Allows describing an index\n",
    "                                'aoss:ReadDocument',  # Allows reading documents from the index\n",
    "                                'aoss:WriteDocument'  # Allows writing documents to the index\n",
    "                            ],\n",
    "                            'ResourceType': 'index'  # Define resource type as index\n",
    "                        }\n",
    "                    ],\n",
    "                    'Principal': [  # Define who has access to this policy\n",
    "                        identity_arn,  # The primary ARN to which the policy applies\n",
    "                        genaibookedbedrocksagemakerexecutionrolearn  # Example of an additional ARN\n",
    "                    ],\n",
    "                    'Description': 'Easy data policy'  # Description of the policy\n",
    "                }\n",
    "            ]\n",
    "        ),\n",
    "        type='data'  \n",
    "    )\n",
    "    \n",
    "    # If the policy is created successfully, print a success message\n",
    "    print(f\"Access policy '{access_policy_name}' created successfully.\")\n",
    "\n",
    "# Handle case where a policy with the same name already exists\n",
    "except aoss_client.exceptions.ConflictException:\n",
    "    print(f\"Access policy '{access_policy_name}' already exists.\")\n",
    "\n",
    "# Handle validation errors during policy creation\n",
    "except aoss_client.exceptions.ValidationException as e:\n",
    "    print(f\"Validation error when creating access policy: {str(e)}\")\n",
    "\n",
    "# Handle any other exceptions that occur during the process\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while creating access policy: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677d7fd3-bb89-4d79-bf1f-fd6ba111d82e",
   "metadata": {},
   "source": [
    "### Create a vector search collection in OpenSearch Serverless\n",
    "\n",
    "##### This code attempts to create a vector search collection in Amazon OpenSearch Serverless using the AWS Boto3 aoss_client. The collection, named vector_store_name, is configured for VECTORSEARCH, a specialized type of collection used for vector-based information retrieval.\n",
    "\n",
    "##### The create_collection method is called with the specified name and type (VECTORSEARCH) and followed by extracting collection details. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c294aa1e-43a7-4d81-b20d-65dc343080c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Try to create a vector search collection in OpenSearch Serverless\n",
    "\n",
    "try:\n",
    "    response = aoss_client.create_collection(\n",
    "        name=vector_store_name,\n",
    "        type='VECTORSEARCH'\n",
    "    )\n",
    "    print(f\"Collection '{vector_store_name}' creation is in progress.\")\n",
    "    print(\"Response:\", response)\n",
    "    \n",
    "    aoss_collection_host = response['createCollectionDetail']['id'] + '.' + aws_region_name + '.aoss.amazonaws.com'\n",
    "    aoss_collectionarn = response['createCollectionDetail']['arn']\n",
    "    \n",
    "    print(f\"aoss_collection_host '{aoss_collection_host}' creation is in progress.\")\n",
    "    print(f\"aoss_collectionarn '{aoss_collectionarn}' creation is in progress.\")\n",
    "    \n",
    "except aoss_client.exceptions.ConflictException:\n",
    "    print(f\"Collection '{vector_store_name}' already exists.\")\n",
    "except aoss_client.exceptions.ValidationException as e:\n",
    "    print(f\"Validation error: {str(e)}\")\n",
    "except aoss_client.exceptions.ServiceQuotaExceededException as e:\n",
    "    print(f\"Service quota exceeded: {str(e)}\")\n",
    "except aoss_client.exceptions.OcuLimitExceededException as e:\n",
    "    print(f\"OCU limit exceeded: {str(e)}\")\n",
    "except aoss_client.exceptions.InternalServerException as e:\n",
    "    print(f\"Internal server error: {str(e)}\")\n",
    "except aoss_client.exceptions.ResourceNotFoundException as e:\n",
    "    print(f\"Resource not found: {str(e)}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f35e1d2-f7e4-494c-887d-45f435089b03",
   "metadata": {},
   "source": [
    "### %store magic command to store the variable for use in other notebook cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5b1da4-2267-4c23-939c-02986a056540",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%store aoss_collection_host aoss_collectionarn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b12467-cbe7-42fe-a77f-ceb115bad5cc",
   "metadata": {},
   "source": [
    "### Collection will take some time to be \"ACTIVE\". So, checking when the collection is \"ACTIVE\" for the next steps.\n",
    "\n",
    "##### This code provides a mechanism to wait for an Amazon OpenSearch Serverless vector search collection to transition to the \"ACTIVE\" state, which is necessary before proceeding with subsequent operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51ffbdf-c872-426d-b3e4-6660812a9f95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Collection will take some time to be \"ACTIVE\". So, checking when the collection is \"ACTIVE\" for the next steps.\n",
    "\n",
    "def interactive_sleep(seconds):\n",
    "    \"\"\"A simple sleep function that could be replaced with more complex logic.\"\"\"\n",
    "    time.sleep(seconds)\n",
    "def wait_for_collection_creation(aoss_client, vector_store_name):\n",
    "    try:\n",
    "        # Initial call to batch_get_collection\n",
    "        response = aoss_client.batch_get_collection(names=[vector_store_name])\n",
    "        \n",
    "        # Periodically check collection status\n",
    "        while response['collectionDetails'][0]['status'] == 'CREATING':\n",
    "            print('Creating collection...')\n",
    "            interactive_sleep(30)\n",
    "            response = aoss_client.batch_get_collection(names=[vector_store_name])\n",
    "        \n",
    "        print(f'\\nCollection successfully created: {vector_store_name}')\n",
    "    \n",
    "    except ClientError as e:\n",
    "        print(f\"An error occurred: {e.response['Error']['Message']}\")\n",
    "    except IndexError:\n",
    "        print(\"No collection details found. Please check the collection name.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {str(e)}\")\n",
    "\n",
    "# Example usage\n",
    "wait_for_collection_creation(aoss_client, vector_store_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdabda37-2819-4ed3-924f-0be0f48a3e5f",
   "metadata": {},
   "source": [
    "# Index Creation on the collection\n",
    "\n",
    "##### This script defines a modular approach to create a KNN (k-Nearest Neighbor) vector index in an Amazon OpenSearch Serverless collection using Python and Boto3. The code provides functions for authentication, OpenSearch client creation, and index management while handling errors gracefully.\n",
    "\n",
    "##### 1. AWS Authentication (get_aws_auth): Retrieves AWS credentials using boto3.Session() and constructs an AWSV4SignerAuth object.\n",
    "##### 2. OpenSearch Client Creation (create_opensearch_client): Establishes a connection to OpenSearch using the provided host and AWS authentication.\n",
    "##### 3. Vector Index Creation (create_vector_index): Checks if the specified index already exists using client.indices.exists()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f91d6e7-8007-4397-b097-76734d4dc20c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "def get_aws_auth(region_name, service):\n",
    "    \"\"\"Retrieve AWS authentication credentials.\"\"\"\n",
    "    try:\n",
    "        credentials = boto3.Session().get_credentials()\n",
    "        awsauth = auth = AWSV4SignerAuth(credentials, region_name, service)\n",
    "        return awsauth\n",
    "    except (NoCredentialsError, PartialCredentialsError) as e:\n",
    "        print(f\"Error retrieving AWS credentials: {e}\")\n",
    "        raise\n",
    "\n",
    "def create_opensearch_client(host, awsauth):\n",
    "    \"\"\"Build the OpenSearch client.\"\"\"\n",
    "    try:\n",
    "        client = OpenSearch(\n",
    "            hosts=[{'host': host, 'port': 443}],\n",
    "            http_auth=awsauth,\n",
    "            use_ssl=True,\n",
    "            verify_certs=True,\n",
    "            connection_class=RequestsHttpConnection,\n",
    "            timeout=300\n",
    "        )\n",
    "        return client\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating OpenSearch client: {e}\")\n",
    "        raise\n",
    "\n",
    "def create_vector_index(client, index_name, index_body):\n",
    "    \"\"\"Create the vector index in OpenSearch.\"\"\"\n",
    "    try:\n",
    "        if not client.indices.exists(index=index_name):\n",
    "            client.indices.create(index=index_name, body=json.dumps(index_body))\n",
    "            print(f\"Index '{index_name}' created successfully.\")\n",
    "        else:\n",
    "            print(f\"Index '{index_name}' already exists.\")\n",
    "    except RequestError as e:\n",
    "        print(f\"Error creating index '{index_name}': {e}\")\n",
    "        raise\n",
    "\n",
    "def create_index():\n",
    "\n",
    "    index_body = {\n",
    "           \"settings\": {\n",
    "              \"index.knn\": \"true\"\n",
    "           },\n",
    "           \"mappings\": {\n",
    "              \"properties\": {\n",
    "                 \"image_vector\": {\n",
    "                    \"type\": \"knn_vector\",\n",
    "                    \"dimension\": 1024 # Embedding size for Amanon Titan Multimodal Embedding G1 model, it is 1,024 (default), 384, 256\n",
    "                 },\n",
    "                 \"description\": {\"type\": \"text\"},\n",
    "                  \"item_id\" : {\"type\": \"text\"},\n",
    "                 \"image_url\": {\"type\": \"text\"}\n",
    "              }\n",
    "           }\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # Get AWS authentication\n",
    "        awsauth = get_aws_auth(aws_region_name, opensearch_service_name)\n",
    "\n",
    "        # Create OpenSearch client\n",
    "        oss_client = create_opensearch_client(aoss_collection_host, awsauth)\n",
    "\n",
    "        # Create index\n",
    "        try:\n",
    "            response = oss_client.indices.create(index=index_name, body=json.dumps(index_body))\n",
    "            print('\\nCreating index:')\n",
    "\n",
    "            # index creation can take up to a minute\n",
    "            interactive_sleep(60)\n",
    "            \n",
    "            print('\\nIndex creation completed.')\n",
    "            \n",
    "            return oss_client \n",
    "        \n",
    "        except RequestError as e:\n",
    "            # you can delete the index if its already exists\n",
    "            # oss_client.indices.delete(index=index_name)\n",
    "            print(f'Error while trying to create the index, with error {e.error}\\nyou may unmark the delete above to delete, and recreate the index')\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during the process: {e}\")\n",
    "\n",
    "oss_client = create_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f44ef87-a689-4400-aea8-aa03e8a925df",
   "metadata": {},
   "source": [
    "# Start an ingestion job\n",
    "\n",
    "##### The code efficiently indexes metadata from a DataFrame into an OpenSearch index. It iterates through the DataFrame rows with a progress bar using tqdm, constructs a document containing the embedding vector, description, item ID, and image path for each record, and indexes it into the specified OpenSearch index. \n",
    "\n",
    "## You should store the image files into S3 in your live project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a911b6-bd95-4c83-b5bc-3eb712f480c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    " try:\n",
    "    # Iterate over the DataFrame rows with a progress bar\n",
    "    for idx, record in tq.tqdm(image_metadata_list_df.iterrows(), total=len(image_metadata_list_df)):\n",
    "        try:\n",
    "            # Construct the document to be indexed\n",
    "            document = {\n",
    "                'image_vector': record['embedding_img'],  # Embedding vector for the image\n",
    "                'description': record['Description'],    # Text description of the image\n",
    "                'item_id': record['ID'],                 # Unique identifier for the item\n",
    "                'image_url': record['Image_path'],       # URL or path to the image\n",
    "            }\n",
    "\n",
    "            # Index the document into the specified OpenSearch index\n",
    "            response = oss_client.index(\n",
    "                index=index_name,  # Target OpenSearch index\n",
    "                body=document      # Document to be indexed\n",
    "            )\n",
    "            # Optionally log success or response details for debugging\n",
    "            print(f\"Document indexed successfully for item_id: {document['item_id']}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            # Handle errors related to indexing a specific document\n",
    "            print(f\"Error indexing document for item_id: {record['ID']}. Error: {e}\")\n",
    "\n",
    "except Exception as e:\n",
    "    # Handle broader errors (e.g., issues with the DataFrame or OpenSearch client)\n",
    "    print(f\"Unexpected error during the indexing process: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1848ae43-df33-4273-8c12-cd4fae216cff",
   "metadata": {},
   "source": [
    "# Use Case 1\n",
    "\n",
    "### Search capability with a simple text prompt\n",
    "\n",
    "    The function get_titan_multimodal_embedding generates multimodal embeddings using AWS Bedrock models by processing either an image or a text description. It accepts parameters like the image path, text description, desired embedding dimensions (default 1024), and the model ID. The function checks if the image file exists and encodes it in base64, while text descriptions are directly added to the request payload. It ensures at least one input is provided and invokes the model via the Bedrock runtime client, combining the input with an embedding configuration. If successful, it returns the model's response as a parsed JSON object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c775d241",
   "metadata": {},
   "source": [
    "Architecture \n",
    "\n",
    "<img src=\"./usecase1_arc_diagram.png\" style=\"width: 600px; height: 400px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4305419a-993f-43a3-bc8b-b101c0f53306",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "def get_titan_multimodal_embedding(\n",
    "    image_path: str = None,  # Maximum image dimensions: 2048 x 2048 pixels\n",
    "    description: str = None,  # Text description in English (max 128 tokens)\n",
    "    dimension: int = 1024,  # Desired embedding dimension (default 1024, other options: 384, 256)\n",
    "    model_id: str = multimodal_embed_model_id  # Predefined model ID for the multimodal embedding\n",
    "):\n",
    "    \"\"\"\n",
    "    Function to obtain multimodal embeddings by providing either an image or a text description.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Path to the image file (optional).\n",
    "        description (str): Text description for embedding (optional).\n",
    "        dimension (int): The dimensionality of the embedding output (default is 1024).\n",
    "        model_id (str): Model identifier for the multimodal embedding model.\n",
    "    \n",
    "    Returns:\n",
    "        dict: The response from the Bedrock model containing the multimodal embeddings.\n",
    "    \n",
    "    Raises:\n",
    "        FileNotFoundError: If the image file does not exist at the given path.\n",
    "        AssertionError: If neither image nor description is provided.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize the payload to send to the model\n",
    "    payload_body = {}\n",
    "\n",
    "    # Embedding configuration with the specified output dimension\n",
    "    embedding_config = {\n",
    "        \"embeddingConfig\": { \n",
    "            \"outputEmbeddingLength\": dimension\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Process image input if provided\n",
    "    if image_path:\n",
    "        # Check if the provided image path exists locally\n",
    "        if os.path.exists(image_path):\n",
    "            # Open the image file in binary mode and encode it in base64\n",
    "            with open(image_path, \"rb\") as image_file:\n",
    "                encoded_image = base64.b64encode(image_file.read()).decode('utf8')\n",
    "            # Add the base64 encoded image to the payload\n",
    "            payload_body[\"inputImage\"] = encoded_image\n",
    "        else:\n",
    "            # Raise an error if the image file does not exist\n",
    "            raise FileNotFoundError(f\"The image file at {image_path} does not exist.\")\n",
    "    \n",
    "    # Process text description input if provided\n",
    "    if description:\n",
    "        payload_body[\"inputText\"] = description\n",
    "\n",
    "    # Ensure that either image or text is provided for the request\n",
    "    assert payload_body, \"Please provide either an image and/or a text description.\"\n",
    "\n",
    "    try:\n",
    "        # Invoke the model using the Bedrock runtime client to get multimodal embeddings\n",
    "        response = boto3_bedrock_runtime_client.invoke_model(\n",
    "            body=json.dumps({**payload_body, **embedding_config}), \n",
    "            modelId=model_id,\n",
    "            accept=\"application/json\", \n",
    "            contentType=\"application/json\"\n",
    "        )\n",
    "        # Return the parsed JSON response from the model\n",
    "        return json.loads(response.get(\"body\").read())\n",
    "\n",
    "    except Exception as e:\n",
    "        # Handle any exceptions that might occur during the model invocation\n",
    "        print(f\"An error occurred while invoking the model: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258f2874-1d4d-4b33-bcad-8b221198d0dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"Men, Apparel, Topwear, Tshirts, White\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992bab3e-41dc-479a-83bd-a89f71f280d4",
   "metadata": {},
   "source": [
    "    The function find_similar_items_from_query performs a semantic search using OpenSearch and Titan's multimodal embedding model to find items similar to a given text query. It first generates a query embedding using get_titan_multimodal_embedding, then constructs a KNN query for OpenSearch using the embedding and specified parameters like top_k and num_results. The function executes the search via the OpenSearch client, excluding image vectors from the response, and processes the results to return a list of similar items, including their scores, IDs, image URLs, and descriptions. It handles errors related to both embedding generation and OpenSearch execution, ensuring robustness in the workflow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7964db0-7019-4bba-80ff-18ae6862fc65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "def find_similar_items_from_query(\n",
    "    query_prompt: str, \n",
    "    top_k: int, \n",
    "    num_results: int, \n",
    "    index_name: str, \n",
    "    dataset, \n",
    "    open_search_client\n",
    ") -> list:\n",
    "    \"\"\"\n",
    "    Perform a semantic search using KNN on an input query prompt to find similar items.\n",
    "    \n",
    "    Args:\n",
    "        query_prompt (str): Input text query for generating embeddings.\n",
    "        top_k (int): Number of top-k similar vectors to retrieve.\n",
    "        num_results (int): Number of search results to return.\n",
    "        index_name (str): Name of the OpenSearch index.\n",
    "        dataset: Metadata dataset for additional lookups.\n",
    "        open_search_client: OpenSearch client for executing queries.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of dictionaries containing similar item details (score, item_id, image_url, description).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Obtain the query embedding for the given text prompt\n",
    "        query_embedding = get_titan_multimodal_embedding(description=query_prompt, dimension=1024)[\"embedding\"]\n",
    "\n",
    "        # Define the OpenSearch KNN query body\n",
    "        query_body = {\n",
    "            \"size\": num_results,\n",
    "            \"_source\": {\n",
    "                \"exclude\": [\"image_vector\"],  # Exclude the image_vector field from the search results\n",
    "            },\n",
    "            \"query\": {\n",
    "                \"knn\": {\n",
    "                    \"image_vector\": {\n",
    "                        \"vector\": query_embedding,  # Query embedding for similarity search\n",
    "                        \"k\": top_k,                 # Number of top-k similar vectors to retrieve\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            # Execute the search in OpenSearch\n",
    "            search_response = open_search_client.search(index=index_name, body=query_body)\n",
    "\n",
    "            # Process the search results\n",
    "            similar_items = []\n",
    "            for hit in search_response[\"hits\"][\"hits\"]:\n",
    "                similar_item = {\n",
    "                    \"score\": hit[\"_score\"],                           # Similarity score\n",
    "                    \"item_id\": hit[\"_source\"][\"item_id\"],             # Unique identifier for the item\n",
    "                    \"image_url\": hit[\"_source\"][\"image_url\"],         # URL of the image\n",
    "                    \"description\": hit[\"_source\"][\"description\"],     # Description of the item\n",
    "                }\n",
    "                similar_items.append(similar_item)\n",
    "\n",
    "            return similar_items\n",
    "\n",
    "        except Exception as search_error:\n",
    "            # Handle errors related to OpenSearch queries\n",
    "            print(f\"Error executing OpenSearch query: {search_error}\")\n",
    "            return []\n",
    "\n",
    "    except Exception as embedding_error:\n",
    "        # Handle errors related to embedding generation\n",
    "        print(f\"Error generating query embedding: {embedding_error}\")\n",
    "        return []\n",
    "\n",
    "# Example usage\n",
    "try:\n",
    "    similar_items_results = find_similar_items_from_query(\n",
    "        query_prompt=prompt,\n",
    "        top_k=5,\n",
    "        num_results=3,\n",
    "        index_name=index_name,\n",
    "        dataset=image_metadata_list,\n",
    "        open_search_client=oss_client,\n",
    "    )\n",
    "\n",
    "    # Print the results or take further actions\n",
    "    print(similar_items_results)\n",
    "\n",
    "except Exception as general_error:\n",
    "    # Handle unexpected errors in the overall process\n",
    "    print(f\"Unexpected error during semantic search: {general_error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0c084c-9558-4816-b4fa-84f6255a3227",
   "metadata": {},
   "source": [
    "    This function, display_similar_items, is designed to display search results one by one with their details. It iterates through the results list and prints each item's score and description. If the image file associated with the result exists locally (verified using os.path.exists), it displays the image using Python's IPython.display.Image module with a width of 300 pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5957c6d0-94ae-4aee-8dcb-b56ef9a281bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Function to display items one by one\n",
    "\n",
    "def display_similar_items(results):\n",
    "    for idx, item in enumerate(results):\n",
    "        print()\n",
    "        print()\n",
    "        print()\n",
    "        print(f\"Item {idx + 1}:\")\n",
    "        print(f\"Score: {item['score']:.4f}\")\n",
    "        print(f\"Description: {item['description']}\")\n",
    "        if os.path.exists(item['image_url']):  # Check if the image file exists\n",
    "            display(Image(filename=item['image_url'], width=300))  # Display image\n",
    "        else:\n",
    "            print(\"Image file not found.\")\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "# Call the function\n",
    "display_similar_items(similar_items_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243fd9b2-79f3-4bbd-b0bb-308ebdb5a0d2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Use Case 2\n",
    "\n",
    "### Search capability features a combination of text and image prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3a18b9",
   "metadata": {},
   "source": [
    "Architecture \n",
    "\n",
    "<img src=\"./usecase2_arc_diagram.png\" style=\"width: 600px; height: 400px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4f585c-e2c6-47ad-b6a1-24ee336852da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Assuming image_metadata_list is a list of dictionaries with an 'ID' column\n",
    "def get_random_id(metadata_list):\n",
    "    \"\"\"\n",
    "    Selects a random ID from the metadata list.\n",
    "\n",
    "    Args:\n",
    "        metadata_list (list): List of dictionaries containing the 'ID' field.\n",
    "\n",
    "    Returns:\n",
    "        str: Randomly selected ID.\n",
    "    \"\"\"\n",
    "    if not metadata_list:\n",
    "        raise ValueError(\"The metadata list is empty.\")\n",
    "    \n",
    "    # Randomly select an item from the list and return its 'ID'\n",
    "    selected_item = random.choice(metadata_list)\n",
    "    return selected_item[\"ID\"]\n",
    "\n",
    "# Get a random ID\n",
    "item_id = get_random_id(image_metadata_list)\n",
    "print(f\"Randomly selected ID: {item_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4438c5-cb37-4bbb-8f69-284c462f33ff",
   "metadata": {},
   "source": [
    "    The code performs a semantic search to find visually similar images using a query image and an OpenSearch index. It first filters a list of metadata dictionaries to locate the image path of the query image. Then, it uses a function, find_similar_items_from_image, which leverages a Titan multimodal embedding function to generate a query embedding for the image. This embedding is used to search an OpenSearch index for the top-k most similar vectors, specified by k and num_results. The function constructs and executes a KNN (k-nearest neighbors) query on the index, processes the search hits, and compiles a list of results containing metadata like score, item ID, image URL, and description for each similar item. Finally, the list of similar items is returned and optionally displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf67c35c-585b-4d5d-a31b-9e397a1dfa25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Filter the list of dictionaries where the 'ID' matches the item_id\n",
    "matching_items = [item for item in image_metadata_list if item[\"ID\"] == item_id]\n",
    "\n",
    "# Print the matching item(s)\n",
    "search_image_path = matching_items[0][\"Image_path\"]\n",
    "\n",
    "# Assuming image_data_list is a list of dictionaries and search_image_path is extracted correctly\n",
    "\n",
    "# Function for semantic search capability using knn on input image prompt\n",
    "def find_similar_items_from_image(image_path: str, k: int, num_results: int, index_name: str, dataset, open_search_client) -> []:\n",
    "    \"\"\"\n",
    "    Main semantic search capability using knn on input image prompt.\n",
    "    Args:\n",
    "        k: number of top-k similar vectors to retrieve from OpenSearch index\n",
    "        num_results: number of the top-k similar vectors to retrieve\n",
    "        index_name: index name in OpenSearch\n",
    "    \"\"\"\n",
    "    # Assuming the get_titan_multimodal_embedding function will work for image paths\n",
    "    query_emb = get_titan_multimodal_embedding(image_path=image_path, dimension=1024)[\"embedding\"]\n",
    "    \n",
    "    body = {\n",
    "        \"size\": num_results,\n",
    "        \"_source\": {\n",
    "            \"exclude\": [\"image_vector\"],\n",
    "        },\n",
    "        \"query\": {\n",
    "            \"knn\": {\n",
    "                \"image_vector\": {\n",
    "                    \"vector\": query_emb,\n",
    "                    \"k\": k,\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "    }\n",
    "    \n",
    "\n",
    "    # Execute search query\n",
    "    res = open_search_client.search(index=index_name, body=body)\n",
    "    \n",
    "    results_list = []\n",
    "\n",
    "    # Iterate through the search hits and collect image data\n",
    "    for hit in res[\"hits\"][\"hits\"]:\n",
    "\n",
    "        \n",
    "        # Initialize an empty list to store the results\n",
    "        results_list = []\n",
    "\n",
    "        # Loop over the hits to process each similar item\n",
    "        for hit in res[\"hits\"][\"hits\"]:\n",
    "        # Initialize a dictionary to store information for each similar item\n",
    "            similar_items_results = {}\n",
    "\n",
    "            # Extract relevant information from the hit\n",
    "            similar_items_results[\"score\"] = hit[\"_score\"]\n",
    "            similar_items_results[\"item_id\"] = hit[\"_source\"][\"item_id\"]\n",
    "            similar_items_results[\"image_url\"] = hit[\"_source\"][\"image_url\"]\n",
    "            similar_items_results[\"description\"] = hit[\"_source\"][\"description\"]\n",
    "\n",
    "            # Optionally, you can retrieve the image and item name as well\n",
    "            # image, item_name = get_image_from_item_id_s3(item_id=similar_items_results[\"item_id\"], dataset=dataset)\n",
    "\n",
    "            # Attach the score and item name as a label to the image if needed\n",
    "            # image.name_and_score = f'{similar_items_results[\"score\"]}:{item_name}'\n",
    "\n",
    "            # Append the results to the list\n",
    "            results_list.append(similar_items_results)\n",
    "\n",
    "    return results_list\n",
    "    \n",
    "\n",
    "# Set the image_path from the matching item (e.g., from your previous search)\n",
    "search_image_path = matching_items[0][\"Image_path\"]\n",
    "\n",
    "# Example usage for similar item search\n",
    "similar_items = find_similar_items_from_image(\n",
    "    image_path=search_image_path,\n",
    "    k=5,\n",
    "    num_results=3,\n",
    "    index_name=index_name,\n",
    "    dataset=image_metadata_list,\n",
    "    open_search_client=oss_client\n",
    ")\n",
    "\n",
    "# Display the retrieved similar images\n",
    "#results_list = display_images(similar_items)\n",
    "\n",
    "print(similar_items)\n",
    "\n",
    "# Call the function\n",
    "display_similar_items(similar_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b411ca-49b7-4c17-b19c-d9ff00d26b60",
   "metadata": {},
   "source": [
    "# End of NoteBook \n",
    "\n",
    "#### <ins>Step 1</ins> \n",
    "\n",
    "##### Please ensure that you close the kernel after using this notebook to avoid any potential charges to your account.\n",
    "\n",
    "##### Process: Go to \"Kernel\" at top option. Choose \"Shut Down Kernel\". \n",
    "##### Refer https://docs.aws.amazon.com/sagemaker/latest/dg/studio-ui.html\n",
    "\n",
    "\n",
    "#### <ins>Step 2</ins> \n",
    "\n",
    "#### If you are not executing any further lab of this Chapter 19\n",
    "##### Uncomment and execute the below steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c599526-3289-4b47-a329-a13922837472",
   "metadata": {},
   "source": [
    "    This script defines two functions to manage OpenSearch Serverless collections: \n",
    "    \n",
    "    extract_collection_id_from_arn(arn) extracts the collection ID from an ARN by splitting the string to retrieve the last segment.\n",
    "    delete_opensearch_collection(aoss_client, collection_arn) uses the extracted ID to delete the collection via the OpenSearch client. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8f78ab-ff89-4dd4-9d9c-29e946170ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def extract_collection_id_from_arn(arn):\n",
    "    \"\"\"Extracts the collection ID from the OpenSearch Serverless ARN.\"\"\"\n",
    "    try:\n",
    "        # The collection ID is the last segment after the \"/\" in the ARN\n",
    "        collection_id = arn.split(\"/\")[-1]\n",
    "        return collection_id\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting collection ID from ARN: {e}\")\n",
    "        return None\n",
    "\n",
    "def delete_opensearch_collection(aoss_client, collection_arn):\n",
    "    \"\"\"Deletes an OpenSearch Serverless collection using its ARN.\"\"\"\n",
    "    # Step 1: Extract the collection ID from the ARN\n",
    "    collection_id = extract_collection_id_from_arn(collection_arn)\n",
    "    \n",
    "    if collection_id is None:\n",
    "        print(\"Invalid collection ARN. Cannot proceed with deletion.\")\n",
    "        return\n",
    "    \n",
    "    # Step 2: Use the OpenSearch client to delete the collection by ID\n",
    "    try:\n",
    "        response = aoss_client.delete_collection(id=collection_id)\n",
    "        print(f\"Collection {collection_id} deleted successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error deleting collection: {e}\")\n",
    "\n",
    "# Call the function to delete the collection\n",
    "delete_opensearch_collection(aoss_client, aoss_collectionarn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d3aad0-6aaa-4f4d-9dfd-f33cf84cc6d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
