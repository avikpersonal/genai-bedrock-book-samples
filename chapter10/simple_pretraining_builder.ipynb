{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ed3a60a-5001-46ff-ae70-61d861a00c53",
   "metadata": {
    "tags": []
   },
   "source": [
    "# File Name: simple_pretraining_builder.ipynb\n",
    "### Location: Chapter 9\n",
    "### Purpose: \n",
    "#####             1. Need to fill up \n",
    "##### Dependency: simple-sageMaker-bedrock.ipynb at Chapter 3 should work properly. \n",
    "# <ins>-----------------------------------------------------------------------------------</ins>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99464e3-0679-4a67-bb38-8d96892eefa5",
   "metadata": {},
   "source": [
    "# <ins>Amazon SageMaker Classic</ins>\n",
    "#### Those who are new to Amazon SageMaker Classic. Follow the link for the details. https://docs.aws.amazon.com/sagemaker/latest/dg/studio.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91003ca1-0026-46eb-bd09-81861135cb22",
   "metadata": {},
   "source": [
    "# <ins>Environment setup of Kernel</ins>\n",
    "##### Fill \"Image\" as \"Data Science\"\n",
    "##### Fill \"Kernel\" as \"Python 3\"\n",
    "##### Fill \"Instance type\" as \"ml-t3-medium\"\n",
    "##### Fill \"Start-up script\" as \"No Scripts\"\n",
    "##### Click \"Select\"\n",
    "\n",
    "###### Refer https://docs.aws.amazon.com/sagemaker/latest/dg/notebooks-create-open.html for details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c865b7f5-755a-498c-bff6-7647281b15b9",
   "metadata": {},
   "source": [
    "# <ins>Mandatory installation on the kernel through pip</ins>\n",
    "\n",
    "##### This lab will work with below software version. But, if you are trying with latest version of boto3, awscli, and botocore. This code may fail. You might need to change the corresponding api. \n",
    "\n",
    "##### You will see pip dependency errors. you can safely ignore these errors and continue executing rest of the cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ade0112-a4be-4ce8-be92-8cbf28b2acfa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pip in /root/.local/lib/python3.11/site-packages (24.3.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/root/.local/lib/python3.11/site-packages/~xhash'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script wsdump is installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script tqdm is installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/root/.local/lib/python3.11/site-packages/~ornado'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script send2trash is installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/root/.local/lib/python3.11/site-packages/~yzmq.libs'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/root/.local/lib/python3.11/site-packages/~mq'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/root/.local/lib/python3.11/site-packages/~aml'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script dotenv is installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script pygmentize is installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/root/.local/lib/python3.11/site-packages/~yarrow'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/root/.local/lib/python3.11/site-packages/~sutil'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/root/.local/lib/python3.11/site-packages/~ropcache'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/root/.local/lib/python3.11/site-packages/~rjson'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script f2py is installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/root/.local/lib/python3.11/site-packages/~umpy.libs'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/root/.local/lib/python3.11/site-packages/~umpy'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/root/.local/lib/python3.11/site-packages/~ultidict'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script pyjson5 is installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/root/.local/lib/python3.11/site-packages/~rozenlist'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The scripts fonttools, pyftmerge, pyftsubset and ttx are installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script debugpy is installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/root/.local/lib/python3.11/site-packages/~ebugpy'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script normalizer is installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/root/.local/lib/python3.11/site-packages/~harset_normalizer'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script pybabel is installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/root/.local/lib/python3.11/site-packages/~arl'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The scripts pyrsa-decrypt, pyrsa-encrypt, pyrsa-keygen, pyrsa-priv2pub, pyrsa-sign and pyrsa-verify are installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/root/.local/lib/python3.11/site-packages/~ydantic_core'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The scripts jupyter, jupyter-migrate and jupyter-troubleshoot are installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/root/.local/lib/python3.11/site-packages/~andas'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The scripts jupyter-kernel, jupyter-kernelspec and jupyter-run are installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The scripts ipython and ipython3 are installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script huggingface-cli is installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script httpx is installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/root/.local/lib/python3.11/site-packages/~iohttp'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script langsmith is installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script jsonschema is installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script jupyter-trust is installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script datasets-cli is installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script jupyter-execute is installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script jupyter-events is installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The scripts jupyter-dejavu and jupyter-nbconvert are installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script langchain-server is installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script jupyter-server is installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The scripts jlpm, jupyter-lab, jupyter-labextension and jupyter-labhub are installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script jupyter-notebook is installed in '/root/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "jupyter-kernel-gateway 2.4.0 requires jupyter-client==6.1.5, but you have jupyter-client 8.6.3 which is incompatible.\n",
      "jupyter-kernel-gateway 2.4.0 requires jupyter-core==4.7.1, but you have jupyter-core 5.7.2 which is incompatible.\n",
      "jupyter-kernel-gateway 2.4.0 requires jupyter-server==1.12.1, but you have jupyter-server 2.14.2 which is incompatible.\n",
      "jupyter-kernel-gateway 2.4.0 requires notebook==6.0.3, but you have notebook 7.3.1 which is incompatible.\n",
      "jupyter-kernel-gateway 2.4.0 requires prompt-toolkit==3.0.36, but you have prompt-toolkit 3.0.48 which is incompatible.\n",
      "jupyter-kernel-gateway 2.4.0 requires pygments==2.14.0, but you have pygments 2.18.0 which is incompatible.\n",
      "jupyter-kernel-gateway 2.4.0 requires tornado==6.1.*, but you have tornado 6.4.2 which is incompatible.\n",
      "jupyter-kernel-gateway 2.4.0 requires traitlets==4.3.3, but you have traitlets 5.14.3 which is incompatible.\n",
      "sagemaker-rsession-gateway 1.0 requires tornado==6.1.0, but you have tornado 6.4.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "CPU times: user 17.8 s, sys: 3.8 s, total: 21.6 s\n",
      "Wall time: 18min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "%pip install --upgrade pip\n",
    "%pip install --no-build-isolation --force-reinstall -q \\\n",
    "    \"boto3>=1.34.84\" \\\n",
    "    \"awscli>=1.32.84\" \\\n",
    "    \"botocore>=1.34.84\" \\\n",
    "    \"langchain\" \\\n",
    "    \"typing_extensions\" \\\n",
    "    \"langchain-community\" \\\n",
    "    \"pypdf\" \\\n",
    "    \"urllib3\" \\\n",
    "    \"jsonlines\" \\\n",
    "    \"datasets\" \\\n",
    "    \"pandas\" \\\n",
    "    \"matplotlib\" \\\n",
    "    \"ipywidgets>=7,<8\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4e3b85-4e64-42ef-9355-ed2a61c68b23",
   "metadata": {},
   "source": [
    "# <ins>Disclaimer</ins>\n",
    "\n",
    "##### You will see pip dependency errors. you can safely ignore these errors and continue executing rest of the cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88ee934-e99c-49ce-9e94-27ffc5baabe1",
   "metadata": {},
   "source": [
    "# <ins>Restart the kernel</ins>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0aaf41bf-d2d2-46fa-b1d4-1dd19c45a069",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>Jupyter.notebook.kernel.restart()</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restart kernel\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5af76d-b2a9-4740-b8bf-134932804719",
   "metadata": {},
   "source": [
    "# <ins>Python package import</ins>\n",
    "\n",
    "##### boto3 offers various clients for Amazon Bedrock to execute various actions.\n",
    "##### botocore is a low-level interface to AWS tools, while boto3 is built on top of botocore and provides additional features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7268959-6ef0-4cbd-bd53-3b31369b4513",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import boto3 \n",
    "import time\n",
    "import pprint\n",
    "from datasets import load_dataset\n",
    "import random\n",
    "import jsonlines\n",
    "import botocore\n",
    "from datetime import datetime\n",
    "from botocore.exceptions import ClientError\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d1b877-deab-4961-a249-7663e812fbb8",
   "metadata": {},
   "source": [
    "### Ignore warning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71587271-9f02-46dc-9eaf-5a5291132f8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b83ea1-9c4e-4ad2-9f83-4dfb0721a166",
   "metadata": {},
   "source": [
    "## Define important environment variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ccf36a8-87e3-462a-9a13-4a286861c327",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boto3_session_name: Session(region_name='us-east-1')\n",
      "aws_region_name: us-east-1\n",
      "boto3_bedrock_client: <botocore.client.Bedrock object at 0x7efe513119d0>\n",
      "random_suffix: 565\n",
      "boto3_bedrock_runtime_client: <botocore.client.BedrockRuntime object at 0x7efe5135b690>\n",
      "s3_suffix: us-east-1-027437746815\n",
      "s3_bucket_name: bedrock-kb-us-east-1-027437746815-565\n",
      "sts_client: <botocore.client.STS object at 0x7efe51380bd0>\n",
      "aws_account_id: 027437746815\n",
      "iam_client: <botocore.client.IAM object at 0x7efe2ef44390>\n",
      "s3_client: <botocore.client.S3 object at 0x7efe2ef7d9d0>\n"
     ]
    }
   ],
   "source": [
    "# Try-except block to handle potential errors\n",
    "try:\n",
    "    # Create a new Boto3 session to interact with AWS services\n",
    "    boto3_session_name = boto3.session.Session()\n",
    "\n",
    "    # Retrieve the current AWS region from the session\n",
    "    aws_region_name = boto3_session_name.region_name\n",
    "    \n",
    "    # Create a new Boto3 bedrock client to interact with AWS services\n",
    "    boto3_bedrock_client = boto3.client('bedrock')\n",
    "    \n",
    "    # Create a new Boto3 bedrock runtime client to interact with AWS services\n",
    "    boto3_bedrock_runtime_client = boto3.client('bedrock-runtime')\n",
    "    \n",
    "    # Create an STS client to interact with AWS Security Token Service (STS)\n",
    "    sts_client = boto3.client('sts')\n",
    "    \n",
    "    # Create an STS client to interact with AWS Security Token Service (STS)\n",
    "    iam_client = boto3.client('iam')\n",
    "    \n",
    "    # Create an S3 client to interact with Amazon S3\n",
    "    s3_client = boto3.client('s3')\n",
    "\n",
    "    # Get the AWS account ID of the caller\n",
    "    aws_account_id = sts_client.get_caller_identity()[\"Account\"]\n",
    "    \n",
    "    # Generate a random suffix number between 200 and 900\n",
    "    random_suffix = random.randrange(200, 900)\n",
    "    \n",
    "    # Generate a suffix using the region and account ID for the S3 bucket name\n",
    "    s3_suffix = f\"{aws_region_name}-{aws_account_id}\"\n",
    "\n",
    "    # Define the name of the S3 bucket (you can replace this with your actual bucket name)\n",
    "    s3_bucket_name = f'bedrock-kb-{s3_suffix}-{random_suffix}'\n",
    "    \n",
    "    # Store all variables in a dictionary\n",
    "    variables_store = {\n",
    "        \"boto3_session_name\": boto3_session_name,\n",
    "        \"aws_region_name\": aws_region_name,\n",
    "        \"boto3_bedrock_client\": boto3_bedrock_client,\n",
    "        \"random_suffix\": random_suffix,\n",
    "        \"boto3_bedrock_runtime_client\": boto3_bedrock_runtime_client,\n",
    "        \"s3_suffix\": s3_suffix,\n",
    "        \"s3_bucket_name\": s3_bucket_name,\n",
    "        \"sts_client\": sts_client,\n",
    "        \"aws_account_id\": aws_account_id,\n",
    "        \"iam_client\":iam_client,\n",
    "        \"s3_client\": s3_client\n",
    "    }\n",
    "\n",
    "    # Print all variables\n",
    "    for var_name, value in variables_store.items():\n",
    "        print(f\"{var_name}: {value}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bf9fb8-552a-4719-8ab7-a1c19c1c4342",
   "metadata": {},
   "source": [
    "### ---------------\n",
    "##### The provided code snippet uses the AWS Boto3 library to manage an Amazon S3 bucket for a knowledge base data source. It begins by creating an S3 client and defines a bucket name, s3_bucket_name. A function, check_bucket_exists, checks whether the specified bucket exists by attempting to retrieve its metadata using the head_bucket method. If the bucket exists, a message is printed confirming its existence. If it does not exist (error code '404'), the function returns False. If the bucket is missing, the script proceeds to create it using the create_bucket method, ensuring the data source bucket is always available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3f72d3f-26d7-4bb1-b924-e6a821291b97",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket 'bedrock-kb-us-east-1-027437746815-565' does not exist.\n",
      "Bucket 'bedrock-kb-us-east-1-027437746815-565' created successfully.\n",
      "CPU times: user 24.9 ms, sys: 1.35 ms, total: 26.3 ms\n",
      "Wall time: 198 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Check if s3 bucket exists, and if not create S3 bucket for knowledge base data source\n",
    "\n",
    "# Try-except block to handle potential errors\n",
    "try:\n",
    "\n",
    "    # Define the bucket name (you can replace this with your actual bucket name)\n",
    "    bucket_name = s3_bucket_name\n",
    "\n",
    "    # Check if the bucket exists\n",
    "    def check_bucket_exists(bucket_name):\n",
    "        try:\n",
    "            s3_client.head_bucket(Bucket=bucket_name)\n",
    "            print(f\"Bucket '{bucket_name}' already exists.\")\n",
    "            return True\n",
    "        except botocore.exceptions.ClientError as e:\n",
    "            error_code = e.response['Error']['Code']\n",
    "            if error_code == '404':\n",
    "                print(f\"Bucket '{bucket_name}' does not exist.\")\n",
    "                return False\n",
    "            else:\n",
    "                raise e\n",
    "\n",
    "    # If the bucket doesn't exist, create it\n",
    "    if not check_bucket_exists(bucket_name):\n",
    "        # Create the S3 bucket\n",
    "        s3_client.create_bucket(Bucket=bucket_name)\n",
    "        print(f\"Bucket '{bucket_name}' created successfully.\")\n",
    "\n",
    "except botocore.exceptions.BotoCoreError as boto_error:\n",
    "    print(f\"An error occurred with Boto3: {boto_error}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec480e3-ea1c-4880-8409-f552be5d6584",
   "metadata": {},
   "source": [
    "# Download and prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "515479fe-ec8c-479e-a92a-a854ad05499a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /root/chapter9\n",
      "Data directory path: /root/chapter9/data/pretraining\n",
      "CPU times: user 1.08 ms, sys: 246 μs, total: 1.33 ms\n",
      "Wall time: 1.47 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Print the current working directory\n",
    "print(f\"Current working directory: {current_directory}\")\n",
    "\n",
    "# Construct the path to 'data/rag_use_cases' inside the current directory\n",
    "data_directory = os.path.join(current_directory, 'data', 'pretraining')\n",
    "\n",
    "# Print the resulting path\n",
    "print(f\"Data directory path: {data_directory}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7224686a-4498-469e-94de-53cd8ece5202",
   "metadata": {},
   "source": [
    "# Understand dataset \n",
    "\n",
    "### Source of the datasets: Amazon-com-Inc-2023-Annual-Report.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "88eecf65-adb6-458e-9730-1bc128cf472d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PDF file: /root/chapter9/data/pretraining/Amazon-com-Inc-2023-Annual-Report.pdf\n",
      "Loaded 92 pages from the document.\n",
      "Document split into 91 chunks.\n",
      "Dataset saved successfully to /root/chapter9/data/pretraining/amazon-annual-report-dataset.jsonl\n",
      "CPU times: user 4.45 s, sys: 82 ms, total: 4.53 s\n",
      "Wall time: 6.35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Define the output file path\n",
    "train_file_name = \"amazon-annual-report-dataset.jsonl\"\n",
    "train_dataset_filename = f\"{data_directory}/{train_file_name}\"\n",
    "sample_file_name = \"Amazon-com-Inc-2023-Annual-Report.pdf\"  \n",
    "sample_dataset_filename = f\"{data_directory}/{sample_file_name}\"\n",
    "\n",
    "# Function to split PDF text and create the dataset file\n",
    "def create_dataset(file_name, dataset_folder=\"data\", chunk_size=20000, chunk_overlap=2000):\n",
    "    try:\n",
    "        # Load the PDF document\n",
    "        print(f\"Loading PDF file: {file_name}\")\n",
    "        loader = PyPDFLoader(file_name)\n",
    "        document = loader.load()\n",
    "        print(f\"Loaded {len(document)} pages from the document.\")\n",
    "\n",
    "        # Split the document into chunks using RecursiveCharacterTextSplitter\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=chunk_size,  # Set chunk size\n",
    "            chunk_overlap=chunk_overlap  # Set overlap for continuity across chunks\n",
    "        )\n",
    "\n",
    "        # Split the document into smaller text chunks\n",
    "        docs = text_splitter.split_documents(document)\n",
    "        print(f\"Document split into {len(docs)} chunks.\")\n",
    "\n",
    "        # Prepare dataset content in the required format {\"input\": \"<input text>\"}\n",
    "        contents = \"\"\n",
    "        for doc in docs:\n",
    "            content = {\"input\": doc.page_content}\n",
    "            contents += (json.dumps(content) + \"\\n\")\n",
    "\n",
    "        # Ensure the dataset folder exists, create if necessary\n",
    "        if not os.path.exists(dataset_folder):\n",
    "            print(f\"Dataset folder '{dataset_folder}' not found. Creating it.\")\n",
    "            os.makedirs(dataset_folder)\n",
    "\n",
    "\n",
    "        # Write the dataset content to a file\n",
    "        with open(train_dataset_filename, \"w\") as file:\n",
    "            file.writelines(contents)\n",
    "            print(f\"Dataset saved successfully to {train_dataset_filename}\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        # Handle file not found error\n",
    "        print(f\"Error: The file {file_name} was not found. Please check the file path. {e}\")\n",
    "    except json.JSONDecodeError as e:\n",
    "        # Handle JSON decoding errors\n",
    "        print(f\"Error: Failed to decode JSON while processing the document. {e}\")\n",
    "    except Exception as e:\n",
    "        # Catch any other unexpected errors\n",
    "        print(f\"Unexpected error occurred while creating the dataset: {e}\")\n",
    "\n",
    "# Example usage\n",
    "create_dataset( sample_dataset_filename, data_directory )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd14e3b1-dd62-415d-b183-afd5a4ad9290",
   "metadata": {},
   "source": [
    "# Disclaimer\n",
    "##### Make Sure that data_directory is pointing to the right path and data files are present. Otherwise, you need to change the above code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87370d19-4c49-42c9-8971-454ac5a11cde",
   "metadata": {
    "tags": []
   },
   "source": [
    "### The code defines a function upload_to_s3 that uploads files to an S3 bucket with error handling for common issues such as missing files or upload failures. The function first checks if the file exists locally. If the file is found, it attempts to upload the file to the S3 bucket using s3_client.upload_file.  After uploading, the function returns the S3 URI for the uploaded file. If any file upload fails, the function returns None. The S3 URIs for the uploaded files (training, validation, and test datasets) are printed if all uploads are successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1fc63c4d-8692-455f-8ed9-9f323932d82c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully uploaded amazon-annual-report-dataset.jsonl to s3://bedrock-kb-us-east-1-027437746815-565/amazon-annual-report-dataset.jsonl\n",
      "S3 URIs for the datasets:\n",
      "Train URI: s3://bedrock-kb-us-east-1-027437746815-565/amazon-annual-report-dataset.jsonl\n",
      "CPU times: user 20.1 ms, sys: 6.2 ms, total: 26.3 ms\n",
      "Wall time: 168 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Function to upload files to S3 with error handling\n",
    "def upload_to_s3(file_name, local_path, s3_bucket, s3_key):\n",
    "    try:\n",
    "        # Check if the file exists locally\n",
    "        if not os.path.exists(local_path):\n",
    "            raise FileNotFoundError(f\"File {local_path} not found.\")\n",
    "        \n",
    "        try:\n",
    "            # Attempt to upload file to S3\n",
    "            s3_client.upload_file(local_path, s3_bucket, s3_key)\n",
    "            print(f\"Successfully uploaded {file_name} to s3://{s3_bucket}/{s3_key}\")\n",
    "            return f\"s3://{s3_bucket}/{s3_key}\"\n",
    "        except boto3.exceptions.S3UploadFailedError as e:\n",
    "            print(f\"S3 upload failed for {file_name}: {e}\")\n",
    "        except boto3.exceptions.NoCredentialsError as e:\n",
    "            print(f\"No AWS credentials found for {file_name}: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error while uploading {file_name}: {e}\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"File not found error for {file_name}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "    \n",
    "    return None  # Return None if upload failed\n",
    "\n",
    "\n",
    "# Upload the files and store their S3 URIs in the respective variables\n",
    "train_file_path_s3_uri = upload_to_s3(train_file_name, os.path.join(data_directory, train_file_name), s3_bucket_name, train_file_name)\n",
    "\n",
    "# If all files are successfully uploaded, print the S3 URIs\n",
    "if train_file_path_s3_uri:\n",
    "    print(\"S3 URIs for the datasets:\")\n",
    "    print(f\"Train URI: {train_file_path_s3_uri}\")\n",
    "else:\n",
    "    print(\"One or more files failed to upload.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5552ca2e-a5e3-40b6-90e7-da417c4ea8ac",
   "metadata": {},
   "source": [
    "# Fine out role ARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a1ba7a26-6622-46d4-b920-3a5b0f429d4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Role: book-demo-GenAIBookBedrockSageMakerExecutionRole-ppFsemKcIlvD | ARN: arn:aws:iam::027437746815:role/book-demo-GenAIBookBedrockSageMakerExecutionRole-ppFsemKcIlvD\n",
      "CPU times: user 23.5 ms, sys: 3.73 ms, total: 27.2 ms\n",
      "Wall time: 100 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Find out IAM role and ARN for this session\n",
    "\n",
    "def find_iam_role_by_name_substring(substring):\n",
    "    try:\n",
    "        # Use list_roles to retrieve IAM roles\n",
    "        response = iam_client.list_roles()\n",
    "\n",
    "        # Filter roles by name that contains the substring\n",
    "        matching_roles = [role for role in response['Roles'] if substring in role['RoleName']]\n",
    "\n",
    "        if matching_roles:\n",
    "            for role in matching_roles:\n",
    "                print(f\"Found Role: {role['RoleName']} | ARN: {role['Arn']}\")\n",
    "                genaibookedbedrocksagemakerexecutionrolearn = role['Arn']\n",
    "        else:\n",
    "            print(f\"No roles found with name containing '{substring}'.\")\n",
    "            \n",
    "        return genaibookedbedrocksagemakerexecutionrolearn\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "\n",
    "# Call the function with the desired substring\n",
    "genaibookedbedrocksagemakerexecutionrolearn = find_iam_role_by_name_substring(\"GenAIBookBedrockSageMakerExecutionRole\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667bfe07-16a0-4e81-ab40-699db813859c",
   "metadata": {},
   "source": [
    "# Define variable for pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "29be2ea3-b5fa-431b-8727-8cd847e35870",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bedrock_llm_foundation_model = \"amazon.titan-text-lite-v1:0:4k\"\n",
    "\n",
    "\n",
    "customization_job_name_suffix = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "bedrock_model_customization_job_name = f\"bedrock-model-pretrain-job-{customization_job_name_suffix}\"\n",
    "bedrock_model_customization_model_name = f\"bedrock-pretrain-model-{customization_job_name_suffix}\"\n",
    "# Select the customization type from \"FINE_TUNING\" or \"CONTINUED_PRE_TRAINING\". \n",
    "bedrock_model_customization_type = \"CONTINUED_PRE_TRAINING\"\n",
    "bedrock_model_provisioned_model_name = f\"bedrock-provisioned-model-{customization_job_name_suffix}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a6898e-cdec-4fbb-ae36-78b2d6dc9b39",
   "metadata": {},
   "source": [
    "### Amazon Titan text model customization hyperparameters:\n",
    "\n",
    "    epochs: The number of complete passes through the training dataset. This parameter can take any integer value between 1 and 10, with a default value of 5.\n",
    "    batchSize: The number of samples processed before updating the model's parameters. It can take any integer value between 1 and 64, with a default value of 1.\n",
    "    learningRate: The rate at which the model's parameters are updated after each batch. This parameter can be any float value between 0.0 and 1.0, with a default value of 1.00E-5.\n",
    "    learningRateWarmupSteps: The number of iterations during which the learning rate is gradually increased to the specified value. This parameter can take any integer value between 0 and 250, with a default value of 5.\n",
    "\n",
    "##### Refer: https://docs.aws.amazon.com/bedrock/latest/userguide/cm-hp-titan-text.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbde0acf-f70f-40d3-b2ac-939df02f3655",
   "metadata": {},
   "source": [
    "#### The code defines the hyperparameters for pretraining the Titan text model, including the number of epochs, batch size, and learning rate. It then specifies the S3 URIs for the training, validation (optional), and output data. The code constructs the necessary configurations for the training and validation datasets and the output location. It attempts to create a model customization job using AWS Bedrock's create_model_customization_job function, providing the required parameters such as the customization type, job name, custom model name, and role ARN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1536ae28-d140-4040-aa0b-5069e3d7f80c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customization job created successfully.\n",
      "{'ResponseMetadata': {'RequestId': '3bf8ff15-42e3-46dc-85b9-e15c84c00188', 'HTTPStatusCode': 201, 'HTTPHeaders': {'date': 'Fri, 06 Dec 2024 14:40:15 GMT', 'content-type': 'application/json', 'content-length': '119', 'connection': 'keep-alive', 'x-amzn-requestid': '3bf8ff15-42e3-46dc-85b9-e15c84c00188'}, 'RetryAttempts': 0}, 'jobArn': 'arn:aws:bedrock:us-east-1:027437746815:model-customization-job/amazon.titan-text-lite-v1:0:4k/mdmwnk0gvrbk'}\n",
      "CPU times: user 14.7 ms, sys: 3.52 ms, total: 18.2 ms\n",
      "Wall time: 236 ms\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "\n",
    "# Define the hyperparameters for pretraining Titan text model\n",
    "hyper_parameters = {\n",
    "    \"epochCount\": \"1\",\n",
    "    \"batchSize\": \"1\",\n",
    "    \"learningRate\": \"0.00003\",\n",
    "}\n",
    "\n",
    "output_file_path_s3_uri = f's3://{s3_bucket_name}/outputs/output-{bedrock_model_customization_model_name}'\n",
    "\n",
    "# Specify your data path for training, validation (optional), and output\n",
    "training_data_config = {\"s3Uri\": train_file_path_s3_uri}\n",
    "\n",
    "\n",
    "output_data_config = {\"s3Uri\": output_file_path_s3_uri}\n",
    "\n",
    "# Try to create the customization job\n",
    "try:\n",
    "    # Create the customization job\n",
    "    training_job_response = boto3_bedrock_client.create_model_customization_job(\n",
    "        customizationType=bedrock_model_customization_type,\n",
    "        jobName=bedrock_model_customization_job_name,\n",
    "        customModelName=bedrock_model_customization_model_name,\n",
    "        roleArn=genaibookedbedrocksagemakerexecutionrolearn,\n",
    "        baseModelIdentifier=bedrock_llm_foundation_model,\n",
    "        hyperParameters=hyper_parameters,\n",
    "        trainingDataConfig=training_data_config,\n",
    "        outputDataConfig=output_data_config\n",
    "    )\n",
    "    \n",
    "    print(\"Customization job created successfully.\")\n",
    "    print(training_job_response)\n",
    "\n",
    "except KeyError as e:\n",
    "    print(f\"Missing required parameter: {e}\")\n",
    "except boto3.exceptions.Boto3Error as e:\n",
    "    print(f\"Boto3 error occurred: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac785e0-f657-4535-a32a-000497256d7d",
   "metadata": {},
   "source": [
    "#### The code checks the status of a pretraining job in a loop until it is no longer \"InProgress.\" It defines a function check_pretraining_job_status() to fetch the job status. Initially, the job status is checked, and if it is \"InProgress,\" the status is checked every 60 seconds. Once the job status is no longer \"InProgress,\" the job details are retrieved, and the output job name is derived from the job ARN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cd00e8-abac-4f5c-9c1f-340846df3eeb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial pretraining job status: InProgress\n",
      "Job is still in progress, checking again after 60 seconds...\n",
      "Current pretraining job status: InProgress\n",
      "Job is still in progress, checking again after 60 seconds...\n",
      "Current pretraining job status: InProgress\n",
      "Job is still in progress, checking again after 60 seconds...\n",
      "Current pretraining job status: InProgress\n",
      "Job is still in progress, checking again after 60 seconds...\n",
      "Current pretraining job status: InProgress\n",
      "Job is still in progress, checking again after 60 seconds...\n",
      "Current pretraining job status: InProgress\n",
      "Job is still in progress, checking again after 60 seconds...\n",
      "Current pretraining job status: InProgress\n",
      "Job is still in progress, checking again after 60 seconds...\n",
      "Current pretraining job status: InProgress\n",
      "Job is still in progress, checking again after 60 seconds...\n",
      "Current pretraining job status: InProgress\n",
      "Job is still in progress, checking again after 60 seconds...\n",
      "Current pretraining job status: InProgress\n",
      "Job is still in progress, checking again after 60 seconds...\n",
      "Current pretraining job status: InProgress\n",
      "Job is still in progress, checking again after 60 seconds...\n",
      "Current pretraining job status: InProgress\n",
      "Job is still in progress, checking again after 60 seconds...\n",
      "Current pretraining job status: InProgress\n",
      "Job is still in progress, checking again after 60 seconds...\n",
      "Current pretraining job status: InProgress\n",
      "Job is still in progress, checking again after 60 seconds...\n",
      "Current pretraining job status: InProgress\n",
      "Job is still in progress, checking again after 60 seconds...\n",
      "Current pretraining job status: InProgress\n",
      "Job is still in progress, checking again after 60 seconds...\n",
      "Current pretraining job status: InProgress\n",
      "Job is still in progress, checking again after 60 seconds...\n",
      "Current pretraining job status: InProgress\n",
      "Job is still in progress, checking again after 60 seconds...\n",
      "Current pretraining job status: InProgress\n",
      "Job is still in progress, checking again after 60 seconds...\n",
      "Current pretraining job status: InProgress\n",
      "Job is still in progress, checking again after 60 seconds...\n",
      "Current pretraining job status: InProgress\n",
      "Job is still in progress, checking again after 60 seconds...\n",
      "Current pretraining job status: InProgress\n",
      "Job is still in progress, checking again after 60 seconds...\n",
      "Current pretraining job status: InProgress\n",
      "Job is still in progress, checking again after 60 seconds...\n",
      "Current pretraining job status: InProgress\n",
      "Job is still in progress, checking again after 60 seconds...\n",
      "Current pretraining job status: InProgress\n",
      "Job is still in progress, checking again after 60 seconds...\n",
      "Current pretraining job status: InProgress\n",
      "Job is still in progress, checking again after 60 seconds...\n",
      "Current pretraining job status: InProgress\n",
      "Job is still in progress, checking again after 60 seconds...\n",
      "Current pretraining job status: InProgress\n",
      "Job is still in progress, checking again after 60 seconds...\n",
      "Current pretraining job status: InProgress\n",
      "Job is still in progress, checking again after 60 seconds...\n",
      "Current pretraining job status: InProgress\n",
      "Job is still in progress, checking again after 60 seconds...\n",
      "Current pretraining job status: InProgress\n",
      "Job is still in progress, checking again after 60 seconds...\n",
      "Current pretraining job status: InProgress\n",
      "Job is still in progress, checking again after 60 seconds...\n",
      "Current pretraining job status: InProgress\n",
      "Job is still in progress, checking again after 60 seconds...\n",
      "Current pretraining job status: InProgress\n",
      "Job is still in progress, checking again after 60 seconds...\n",
      "Current pretraining job status: InProgress\n",
      "Job is still in progress, checking again after 60 seconds...\n",
      "Current pretraining job status: InProgress\n",
      "Job is still in progress, checking again after 60 seconds...\n",
      "Current pretraining job status: InProgress\n",
      "Job is still in progress, checking again after 60 seconds...\n",
      "Current pretraining job status: InProgress\n",
      "Job is still in progress, checking again after 60 seconds...\n",
      "Current pretraining job status: InProgress\n",
      "Job is still in progress, checking again after 60 seconds...\n",
      "Current pretraining job status: InProgress\n",
      "Job is still in progress, checking again after 60 seconds...\n",
      "Current pretraining job status: InProgress\n",
      "Job is still in progress, checking again after 60 seconds...\n",
      "Current pretraining job status: InProgress\n",
      "Job is still in progress, checking again after 60 seconds...\n",
      "Current pretraining job status: InProgress\n",
      "Job is still in progress, checking again after 60 seconds...\n",
      "Current pretraining job status: InProgress\n",
      "Job is still in progress, checking again after 60 seconds...\n",
      "Current pretraining job status: InProgress\n",
      "Job is still in progress, checking again after 60 seconds...\n",
      "Current pretraining job status: InProgress\n",
      "Job is still in progress, checking again after 60 seconds...\n",
      "Current pretraining job status: InProgress\n",
      "Job is still in progress, checking again after 60 seconds...\n",
      "Current pretraining job status: InProgress\n",
      "Job is still in progress, checking again after 60 seconds...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "\n",
    "# Function to check the status of the pretraining job\n",
    "def check_pretraining_job_status(job_name):\n",
    "    try:\n",
    "        # Fetch the current status of the pretraining job\n",
    "        job_status = boto3_bedrock_client.get_model_customization_job(jobIdentifier=job_name)[\"status\"]\n",
    "        return job_status\n",
    "    except KeyError as e:\n",
    "        print(f\"Error: Missing expected data in the response: {e}\")\n",
    "    except boto3.exceptions.Boto3Error as e:\n",
    "        print(f\"Boto3 error occurred: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error occurred while fetching job status: {e}\")\n",
    "    return None\n",
    "\n",
    "# Check the initial job status\n",
    "pretraining_job = check_pretraining_job_status(bedrock_model_customization_job_name)\n",
    "if pretraining_job:\n",
    "    print(f\"Initial pretraining job status: {pretraining_job}\")\n",
    "\n",
    "    # Loop to check the status every 60 seconds until the job is no longer \"InProgress\"\n",
    "    while pretraining_job == \"InProgress\":\n",
    "        print(\"Job is still in progress, checking again after 60 seconds...\")\n",
    "        time.sleep(60)  # Wait for 60 seconds before checking the status again\n",
    "        pretraining_job = check_pretraining_job_status(bedrock_model_customization_job_name)\n",
    "        if pretraining_job:\n",
    "            print(f\"Current pretraining job status: {pretraining_job}\")\n",
    "    \n",
    "    # Once the job is no longer \"InProgress\", fetch and display the final job details\n",
    "    if pretraining_job != \"InProgress\":\n",
    "        pretraining_job_details = boto3_bedrock_client.get_model_customization_job(jobIdentifier=bedrock_model_customization_job_name)\n",
    "        print(pretraining_job_details)  \n",
    "        output_job_name = \"model-customization-job-\" + pretraining_job_details['jobArn'].split('/')[-1]\n",
    "        print(f\"Output job name: {output_job_name}\")\n",
    "else:\n",
    "    print(\"Error: Could not retrieve the pretraining job status.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc926cb4-7380-437a-be3c-74eab17b5097",
   "metadata": {},
   "source": [
    "# Test not done this point onwards\n",
    "\n",
    "# Test not done this point onwards\n",
    "\n",
    "# Test not done this point onwards\n",
    "\n",
    "# Test not done this point onwards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5210e919-256e-4b86-bae5-83675541dc5a",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Provisioned throughput is required not only for evaluating the model's performance but also for handling custom model inferences. You specify provisioned throughput in Model Units (MU), where each model unit defines the throughput capacity for a given model. The MU determines the number of input and output tokens the model can process and generate per minute.\n",
    "\n",
    "#### For custom models, provisioned throughput ensures that the model can handle inference requests efficiently, especially when dealing with large volumes of data or high-frequency requests. Without sufficient throughput, the model may experience delays or be unable to process requests within an acceptable timeframe.\n",
    "\n",
    "#### Model unit quotas depend on the level of commitment to provisioned throughput. For custom models with no commitment, you are allocated one model unit per throughput, with a limit of two provisioned throughputs per account. For custom models with commitment, the default quota is 0 model units, and you may request an increase if necessary.\n",
    "\n",
    "#### Provisioned throughput is also required after a customization job is finished, to ensure the pretraining model can be used effectively for inference. You can create provisioned throughput either through the AWS console or using the relevant API call. It typically takes around 20-30 minutes to complete the provisioning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85321741-dab0-48f6-a434-e8b6b5facea6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Retrieve the custom model ARN (model identifier)\n",
    "try:\n",
    "    custom_model_id_arn = boto3_bedrock_client.get_custom_model(modelIdentifier=bedrock_model_customization_model_name)['modelArn']\n",
    "    print(f\"Custom model ARN: {custom_model_id_arn}\")\n",
    "except KeyError as e:\n",
    "    print(f\"Error: Custom model with identifier {bedrock_model_customization_model_name} not found: {e}\")\n",
    "except boto3.exceptions.Boto3Error as e:\n",
    "    print(f\"Boto3 error occurred while fetching model ARN: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error occurred: {e}\")\n",
    "\n",
    "# Create Provisioned Throughput\n",
    "try:\n",
    "    # Create provisioned throughput for the model\n",
    "    provisioned_model_response = boto3_bedrock_client.create_provisioned_model_throughput(\n",
    "        modelUnits=1,\n",
    "        provisionedModelName=bedrock_model_provisioned_model_name,\n",
    "        modelId=bedrock_llm_foundation_model\n",
    "    )\n",
    "    provisioned_model_id_arn = provisioned_model_response['provisionedModelArn']\n",
    "    print(f\"Provisioned throughput ARN: {provisioned_model_id_arn}\")\n",
    "    \n",
    "except KeyError as e:\n",
    "    print(f\"Error: Failed to create provisioned throughput: {e}\")\n",
    "except boto3.exceptions.Boto3Error as e:\n",
    "    print(f\"Boto3 error occurred while creating provisioned throughput: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error occurred: {e}\")\n",
    "\n",
    "# Check the status of the provisioned throughput until it's completed\n",
    "try:\n",
    "    status_provisioning = boto3_bedrock_client.get_provisioned_model_throughput(provisionedModelId=provisioned_model_id_arn)['status']\n",
    "    print(f\"Provisioned throughput status: {status_provisioning}\")\n",
    "\n",
    "    while status_provisioning == 'Creating':\n",
    "        time.sleep(60)  # Wait for a minute before checking the status again\n",
    "        status_provisioning = boto3_bedrock_client.get_provisioned_model_throughput(provisionedModelId=provisioned_model_id_arn)['status']\n",
    "        print(f\"Provisioned throughput status: {status_provisioning}\")\n",
    "        time.sleep(60)  # Wait for another minute before the next status check\n",
    "\n",
    "except KeyError as e:\n",
    "    print(f\"Error: Failed to retrieve provisioning status: {e}\")\n",
    "except boto3.exceptions.Boto3Error as e:\n",
    "    print(f\"Boto3 error occurred while checking provisioning status: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error occurred while checking provisioning status: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd8464c-6cb6-4864-9036-01e3b9d38d13",
   "metadata": {},
   "source": [
    "#### The provided code demonstrates how to invoke both a pretraining model and a base model using the AWS Bedrock service. First, it loads test data, extracting the prompt and reference summary for the model evaluation. The prompt is used to create the request body for invoking the models. The base model's ARN is specified, and the body includes parameters such as maxTokenCount, stopSequences, and others to control the generation. It then uses the boto3 client to invoke both the pretraining model and the base model. The responses are parsed, and the results from both models, along with the reference summary, are printed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68bcf48-dd3e-444a-b89f-33270db8f7af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Invoke the Custom Model\n",
    "try:\n",
    "    # Load test data and extract prompt and reference summary\n",
    "    with open(test_file_path) as f:\n",
    "        lines = f.read().splitlines()\n",
    "    \n",
    "    # Get the prompt and reference summary from the test data\n",
    "    test_prompt = json.loads(lines[10])['prompt']\n",
    "    reference_summary = json.loads(lines[3])['completion']\n",
    "    print(\"Test prompt: \", test_prompt)\n",
    "    print(\"\\n\\n\")\n",
    "    print(\"Reference summary: \", reference_summary)\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "    # Prepare the prompt for model invocation\n",
    "    prompt = f\"{test_prompt}\"\n",
    "\n",
    "    # Define the base model ARN\n",
    "    bedrock_llm_foundation_model_arn = f'arn:aws:bedrock:{aws_region_name}::foundation-model/{bedrock_llm_foundation_model}'\n",
    "\n",
    "    # Create the body for the model invocation request\n",
    "    body = json.dumps({\n",
    "        \"inputText\": prompt,\n",
    "        \"textGenerationConfig\": {\n",
    "            \"maxTokenCount\": 2048,\n",
    "            \"stopSequences\": ['User:'],\n",
    "            \"temperature\": 0,\n",
    "            \"topP\": 0.9\n",
    "        }\n",
    "    })\n",
    "\n",
    "    # Set request headers\n",
    "    accept = 'application/json'\n",
    "    contentType = 'application/json'\n",
    "\n",
    "    # Invoke the pretraining model\n",
    "    pretraining_response = boto3_bedrock_runtime_client.invoke_model(\n",
    "        body=body, \n",
    "        modelId=provisioned_model_id_arn, \n",
    "        accept=accept, \n",
    "        contentType=contentType\n",
    "    )\n",
    "\n",
    "    # Invoke the base model\n",
    "    base_model_response = boto3_bedrock_runtime_client.invoke_model(\n",
    "        body=body, \n",
    "        modelId=bedrock_llm_foundation_model_arn, \n",
    "        accept=accept, \n",
    "        contentType=contentType\n",
    "    )\n",
    "\n",
    "    # Parse the responses from both models\n",
    "    pretraining_response_body = json.loads(pretraining_response.get('body').read())\n",
    "    base_model_response_body = json.loads(base_model_response.get('body').read())\n",
    "\n",
    "    # Print the responses from the models\n",
    "    print(\"Base model response: \", base_model_response_body[\"results\"][0][\"outputText\"] + '\\n')\n",
    "    print(\"\\n\\n\")\n",
    "    print(\"pretraining model response:\", pretraining_response_body[\"results\"][0][\"outputText\"] + '\\n')\n",
    "    print(\"\\n\\n\")\n",
    "    print(\"Reference summary from test data: \", reference_summary)\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: Test file not found at {test_file_path}: {e}\")\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"Error: Failed to decode JSON from the test file: {e}\")\n",
    "except boto3.exceptions.Boto3Error as e:\n",
    "    print(f\"Boto3 error occurred while invoking the model: {e}\")\n",
    "except KeyError as e:\n",
    "    print(f\"Error: Missing key in the model response: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error occurred: {e}\")'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b411ca-49b7-4c17-b19c-d9ff00d26b60",
   "metadata": {},
   "source": [
    "# End of NoteBook \n",
    "\n",
    "#### <ins>Step 1</ins> \n",
    "\n",
    "##### Please ensure that you close the kernel after using this notebook to avoid any potential charges to your account.\n",
    "\n",
    "##### Process: Go to \"Kernel\" at top option. Choose \"Shut Down Kernel\". \n",
    "##### Refer https://docs.aws.amazon.com/sagemaker/latest/dg/studio-ui.html\n",
    "\n",
    "\n",
    "#### <ins>Step 2</ins> \n",
    "\n",
    "#### If you are not executing any further lab of this Chapter 10\n",
    "##### Uncomment and execute the below code to delete the provision thoughtput and custom model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca85e69-9e7d-4591-9110-ba358e3b47cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "%%time \n",
    "\n",
    "# Function to delete provisioned throughput\n",
    "def delete_provisioned_throughput(provisioned_model_id):\n",
    "    try:\n",
    "        # Attempt to delete provisioned model throughput\n",
    "        print(f\"Attempting to delete provisioned throughput for model ID: {provisioned_model_id}\")\n",
    "        response = boto3_bedrock_client.delete_provisioned_model_throughput(provisionedModelId=provisioned_model_id)\n",
    "        \n",
    "        # Log the response if successful\n",
    "        print(\"Provisioned throughput deletion successful. Response:\")\n",
    "        print(response)\n",
    "        \n",
    "    except ClientError as e:\n",
    "        # Handle client error (e.g., invalid request or resource not found)\n",
    "        print(f\"Client error occurred while deleting provisioned throughput: {e}\")\n",
    "    except Exception as e:\n",
    "        # Handle any other unexpected errors\n",
    "        print(f\"Unexpected error occurred while deleting provisioned throughput: {e}\")\n",
    "\n",
    "# Function to delete a custom model\n",
    "def delete_custom_model(model_identifier):\n",
    "    try:\n",
    "        # Attempt to delete the custom model\n",
    "        print(f\"Attempting to delete custom model with identifier: {model_identifier}\")\n",
    "        response = boto3_bedrock_client.delete_custom_model(modelIdentifier=model_identifier)\n",
    "        \n",
    "        # Log the response if successful\n",
    "        print(\"Custom model deletion successful. Response:\")\n",
    "        print(response)\n",
    "        \n",
    "    except ClientError as e:\n",
    "        # Handle client error (e.g., invalid request or resource not found)\n",
    "        print(f\"Client error occurred while deleting custom model: {e}\")\n",
    "    except Exception as e:\n",
    "        # Handle any other unexpected errors\n",
    "        print(f\"Unexpected error occurred while deleting custom model: {e}\")\n",
    "\n",
    "# Delete provisioned throughput for the custom model\n",
    "delete_provisioned_throughput(provisioned_model_id_arn)\n",
    "\n",
    "# Delete the custom model\n",
    "delete_custom_model(bedrock_model_customization_model_name)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd2a004-c7a1-4a69-9e4f-bbdde85c3ebc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
